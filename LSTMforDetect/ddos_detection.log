2025-05-30 00:35:28,878 - __main__ - INFO - 使用设备: cuda
2025-05-30 00:35:28,878 - __main__ - INFO - 加载数据集...
2025-05-30 00:35:28,878 - data - INFO - 开始数据处理流水线，模式: 训练
2025-05-30 00:35:28,878 - data - INFO - 开始读取文件: train_dataset.csv
2025-05-30 00:35:28,886 - data - INFO - CSV文件包含 45 个列
2025-05-30 00:35:28,886 - data - INFO - 将读取 45 列: 44 个特征列和 1 个标签列
2025-05-30 00:35:29,332 - data - INFO - 文件 train_dataset.csv 读取完成，shape=(192000, 45)
2025-05-30 00:35:29,336 - data - INFO - 开始数据清洗
2025-05-30 00:35:29,336 - data - INFO - 原始数据形状: (192000, 45)
2025-05-30 00:35:29,550 - data - INFO - 移除重复记录后剩余 191996 条记录
2025-05-30 00:35:29,564 - data - INFO - 处理前缺失值总数: 0
2025-05-30 00:35:29,771 - data - INFO - 处理了 364441 个异常值
2025-05-30 00:35:29,771 - data - INFO - 数据清洗完成，最终形状: (191996, 45)
2025-05-30 00:35:29,771 - data - INFO - 开始特征预处理
2025-05-30 00:35:29,819 - data - INFO - 对特征 ' Protocol' 进行独热编码，生成 3 个新特征
2025-05-30 00:35:29,854 - data - INFO - 标签类别: ['BENIGN', 'DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDP-lag']
2025-05-30 00:35:29,854 - data - INFO - 类别数量: 12
2025-05-30 00:35:29,967 - data - INFO - 找到 46 个数值特征
2025-05-30 00:35:30,099 - data - INFO - 保存了 46 个数值特征的顺序和scaler
2025-05-30 00:35:30,133 - data - INFO - 执行 PCA 降维: 从 46 维降至 30 维
2025-05-30 00:35:30,832 - data - INFO - PCA降维后保留信息量: 99.98%
2025-05-30 00:35:30,858 - data - INFO - PCA降维完成，最终特征维数: 30
2025-05-30 00:35:30,858 - data - INFO - 标签one-hot编码维数: 12
2025-05-30 00:35:30,915 - data - INFO - 最终特征形状: (191996, 30), 标签形状: (191996, 12)
2025-05-30 00:35:30,915 - data - INFO - 类别数量: 12
2025-05-30 00:35:30,915 - data - INFO - 数据处理流水线完成
2025-05-30 00:35:30,925 - data - INFO - 保存预处理器到: ./outputs\preprocessor.pkl
2025-05-30 00:35:30,927 - data - INFO - 预处理器已保存至 ./outputs\preprocessor.pkl
2025-05-30 00:35:30,927 - data - INFO - 预处理器保存成功
2025-05-30 00:35:30,927 - data - INFO - 特征数据类型: float64
2025-05-30 00:35:30,927 - data - INFO - 标签数据类型: float64
2025-05-30 00:35:30,936 - data - INFO - 特征形状: torch.Size([191996, 30]), 类型: torch.float32
2025-05-30 00:35:30,937 - data - INFO - 标签形状: torch.Size([191996, 12]), 类型: torch.float32
2025-05-30 00:35:30,937 - data - INFO - 标签类别数: 12
2025-05-30 00:35:30,937 - __main__ - INFO - 训练数据集大小: 191996
2025-05-30 00:35:30,937 - data - INFO - 加载预处理器从: ./outputs\preprocessor.pkl
2025-05-30 00:35:30,937 - data - INFO - 预处理器已从 ./outputs\preprocessor.pkl 加载，PCA维度: 30
2025-05-30 00:35:30,937 - data - INFO - 预处理器加载成功
2025-05-30 00:35:30,937 - data - INFO - 开始数据处理流水线，模式: 验证
2025-05-30 00:35:30,937 - data - INFO - 开始读取文件: test_dataset.csv
2025-05-30 00:35:30,942 - data - INFO - CSV文件包含 45 个列
2025-05-30 00:35:30,942 - data - INFO - 将读取 45 列: 44 个特征列和 1 个标签列
2025-05-30 00:35:31,053 - data - INFO - 文件 test_dataset.csv 读取完成，shape=(48000, 45)
2025-05-30 00:35:31,054 - data - INFO - 开始数据清洗
2025-05-30 00:35:31,054 - data - INFO - 原始数据形状: (48000, 45)
2025-05-30 00:35:31,092 - data - INFO - 移除重复记录后剩余 47999 条记录
2025-05-30 00:35:31,096 - data - INFO - 处理前缺失值总数: 0
2025-05-30 00:35:31,169 - data - INFO - 处理了 90815 个异常值
2025-05-30 00:35:31,169 - data - INFO - 数据清洗完成，最终形状: (47999, 45)
2025-05-30 00:35:31,169 - data - INFO - 开始特征预处理
2025-05-30 00:35:31,207 - data - INFO - 找到 46 个数值特征
2025-05-30 00:35:31,209 - data - INFO - 验证阶段使用 46 个特征
2025-05-30 00:35:31,270 - data - INFO - PCA降维完成，最终特征维数: 30
2025-05-30 00:35:31,270 - data - INFO - 标签one-hot编码维数: 12
2025-05-30 00:35:31,289 - data - INFO - 最终特征形状: (47999, 30), 标签形状: (47999, 12)
2025-05-30 00:35:31,289 - data - INFO - 类别数量: 12
2025-05-30 00:35:31,289 - data - INFO - 数据处理流水线完成
2025-05-30 00:35:31,292 - data - INFO - 特征数据类型: float64
2025-05-30 00:35:31,292 - data - INFO - 标签数据类型: float64
2025-05-30 00:35:31,295 - data - INFO - 特征形状: torch.Size([47999, 30]), 类型: torch.float32
2025-05-30 00:35:31,295 - data - INFO - 标签形状: torch.Size([47999, 12]), 类型: torch.float32
2025-05-30 00:35:31,295 - data - INFO - 标签类别数: 12
2025-05-30 00:35:31,295 - __main__ - INFO - 验证数据集大小: 47999
2025-05-30 00:35:31,295 - __main__ - INFO - 样本形状: torch.Size([30, 1]), 标签形状: torch.Size([12])
2025-05-30 00:35:31,295 - __main__ - INFO - 检测到 12 个类别
2025-05-30 00:35:31,296 - __main__ - INFO - 初始化LSTM模型...
2025-05-30 00:35:31,322 - model - INFO - 初始化GRUDetector: input_size=1, hidden_size=128, num_layers=2, num_classes=12, dropout_rate=0.5, bidirectional=True, model_type=gru
2025-05-30 00:35:33,003 - trainer - INFO - LSTM训练器初始化完成，设备: cuda, 学习率: 0.001, 权重衰减: 0.001, 梯度裁剪值: 1.0
2025-05-30 00:35:33,003 - __main__ - INFO - 开始训练LSTM模型...
2025-05-30 00:35:33,003 - trainer - INFO - 开始训练 8 个epochs...
2025-05-30 00:35:33,003 - trainer - INFO - 
Epoch 1/8
2025-05-30 00:35:45,496 - trainer - INFO - Epoch: 1 | Batch: 50/1500 | Loss: 2.1177 | Acc: 27.92% | Time: 12.49s
2025-05-30 00:35:45,930 - trainer - INFO - Epoch: 1 | Batch: 100/1500 | Loss: 1.8124 | Acc: 36.18% | Time: 12.93s
2025-05-30 00:35:46,368 - trainer - INFO - Epoch: 1 | Batch: 150/1500 | Loss: 1.6303 | Acc: 41.38% | Time: 13.36s
2025-05-30 00:35:46,804 - trainer - INFO - Epoch: 1 | Batch: 200/1500 | Loss: 1.5140 | Acc: 45.07% | Time: 13.80s
2025-05-30 00:35:47,240 - trainer - INFO - Epoch: 1 | Batch: 250/1500 | Loss: 1.4289 | Acc: 47.66% | Time: 14.24s
2025-05-30 00:35:47,680 - trainer - INFO - Epoch: 1 | Batch: 300/1500 | Loss: 1.3658 | Acc: 49.74% | Time: 14.68s
2025-05-30 00:35:48,120 - trainer - INFO - Epoch: 1 | Batch: 350/1500 | Loss: 1.3118 | Acc: 51.50% | Time: 15.12s
2025-05-30 00:35:48,558 - trainer - INFO - Epoch: 1 | Batch: 400/1500 | Loss: 1.2717 | Acc: 52.78% | Time: 15.55s
2025-05-30 00:35:48,995 - trainer - INFO - Epoch: 1 | Batch: 450/1500 | Loss: 1.2361 | Acc: 53.84% | Time: 15.99s
2025-05-30 00:35:49,435 - trainer - INFO - Epoch: 1 | Batch: 500/1500 | Loss: 1.2059 | Acc: 54.75% | Time: 16.43s
2025-05-30 00:35:49,873 - trainer - INFO - Epoch: 1 | Batch: 550/1500 | Loss: 1.1812 | Acc: 55.50% | Time: 16.87s
2025-05-30 00:35:50,311 - trainer - INFO - Epoch: 1 | Batch: 600/1500 | Loss: 1.1584 | Acc: 56.30% | Time: 17.31s
2025-05-30 00:35:50,748 - trainer - INFO - Epoch: 1 | Batch: 650/1500 | Loss: 1.1394 | Acc: 56.96% | Time: 17.74s
2025-05-30 00:35:51,185 - trainer - INFO - Epoch: 1 | Batch: 700/1500 | Loss: 1.1244 | Acc: 57.44% | Time: 18.18s
2025-05-30 00:35:51,624 - trainer - INFO - Epoch: 1 | Batch: 750/1500 | Loss: 1.1081 | Acc: 57.97% | Time: 18.62s
2025-05-30 00:35:52,061 - trainer - INFO - Epoch: 1 | Batch: 800/1500 | Loss: 1.0938 | Acc: 58.42% | Time: 19.06s
2025-05-30 00:35:52,499 - trainer - INFO - Epoch: 1 | Batch: 850/1500 | Loss: 1.0812 | Acc: 58.85% | Time: 19.50s
2025-05-30 00:35:52,934 - trainer - INFO - Epoch: 1 | Batch: 900/1500 | Loss: 1.0699 | Acc: 59.24% | Time: 19.93s
2025-05-30 00:35:53,370 - trainer - INFO - Epoch: 1 | Batch: 950/1500 | Loss: 1.0588 | Acc: 59.68% | Time: 20.37s
2025-05-30 00:35:53,808 - trainer - INFO - Epoch: 1 | Batch: 1000/1500 | Loss: 1.0499 | Acc: 59.99% | Time: 20.80s
2025-05-30 00:35:54,244 - trainer - INFO - Epoch: 1 | Batch: 1050/1500 | Loss: 1.0398 | Acc: 60.33% | Time: 21.24s
2025-05-30 00:35:54,682 - trainer - INFO - Epoch: 1 | Batch: 1100/1500 | Loss: 1.0314 | Acc: 60.62% | Time: 21.68s
2025-05-30 00:35:55,117 - trainer - INFO - Epoch: 1 | Batch: 1150/1500 | Loss: 1.0236 | Acc: 60.93% | Time: 22.11s
2025-05-30 00:35:55,555 - trainer - INFO - Epoch: 1 | Batch: 1200/1500 | Loss: 1.0158 | Acc: 61.20% | Time: 22.55s
2025-05-30 00:35:55,991 - trainer - INFO - Epoch: 1 | Batch: 1250/1500 | Loss: 1.0080 | Acc: 61.49% | Time: 22.99s
2025-05-30 00:35:56,427 - trainer - INFO - Epoch: 1 | Batch: 1300/1500 | Loss: 1.0015 | Acc: 61.69% | Time: 23.42s
2025-05-30 00:35:56,863 - trainer - INFO - Epoch: 1 | Batch: 1350/1500 | Loss: 0.9954 | Acc: 61.93% | Time: 23.86s
2025-05-30 00:35:57,300 - trainer - INFO - Epoch: 1 | Batch: 1400/1500 | Loss: 0.9889 | Acc: 62.16% | Time: 24.30s
2025-05-30 00:35:57,737 - trainer - INFO - Epoch: 1 | Batch: 1450/1500 | Loss: 0.9825 | Acc: 62.38% | Time: 24.73s
2025-05-30 00:35:58,180 - trainer - INFO - Epoch: 1 | Batch: 1500/1500 | Loss: 0.9766 | Acc: 62.58% | Time: 25.18s
2025-05-30 00:36:11,704 - trainer - INFO - 验证 | Loss: 0.7474 | Acc: 69.92%
2025-05-30 00:36:11,716 - trainer - INFO - 最佳模型已保存，epoch 1，验证损失: 0.7474
2025-05-30 00:36:11,716 - trainer - INFO - 
Epoch 2/8
2025-05-30 00:36:23,701 - trainer - INFO - Epoch: 2 | Batch: 50/1500 | Loss: 0.8057 | Acc: 68.83% | Time: 11.99s
2025-05-30 00:36:24,204 - trainer - INFO - Epoch: 2 | Batch: 100/1500 | Loss: 0.8051 | Acc: 68.63% | Time: 12.49s
2025-05-30 00:36:24,703 - trainer - INFO - Epoch: 2 | Batch: 150/1500 | Loss: 0.8092 | Acc: 68.55% | Time: 12.99s
2025-05-30 00:36:25,181 - trainer - INFO - Epoch: 2 | Batch: 200/1500 | Loss: 0.8065 | Acc: 68.61% | Time: 13.47s
2025-05-30 00:36:25,666 - trainer - INFO - Epoch: 2 | Batch: 250/1500 | Loss: 0.8020 | Acc: 68.86% | Time: 13.95s
2025-05-30 00:36:26,113 - trainer - INFO - Epoch: 2 | Batch: 300/1500 | Loss: 0.8050 | Acc: 68.79% | Time: 14.40s
2025-05-30 00:36:26,590 - trainer - INFO - Epoch: 2 | Batch: 350/1500 | Loss: 0.8005 | Acc: 68.91% | Time: 14.87s
2025-05-30 00:36:27,063 - trainer - INFO - Epoch: 2 | Batch: 400/1500 | Loss: 0.8012 | Acc: 68.95% | Time: 15.35s
2025-05-30 00:36:27,519 - trainer - INFO - Epoch: 2 | Batch: 450/1500 | Loss: 0.7995 | Acc: 69.07% | Time: 15.80s
2025-05-30 00:36:27,992 - trainer - INFO - Epoch: 2 | Batch: 500/1500 | Loss: 0.7981 | Acc: 69.10% | Time: 16.28s
2025-05-30 00:36:28,480 - trainer - INFO - Epoch: 2 | Batch: 550/1500 | Loss: 0.7968 | Acc: 69.14% | Time: 16.76s
2025-05-30 00:36:28,948 - trainer - INFO - Epoch: 2 | Batch: 600/1500 | Loss: 0.7973 | Acc: 69.11% | Time: 17.23s
2025-05-30 00:36:29,426 - trainer - INFO - Epoch: 2 | Batch: 650/1500 | Loss: 0.7941 | Acc: 69.22% | Time: 17.71s
2025-05-30 00:36:29,877 - trainer - INFO - Epoch: 2 | Batch: 700/1500 | Loss: 0.7933 | Acc: 69.24% | Time: 18.16s
2025-05-30 00:36:30,323 - trainer - INFO - Epoch: 2 | Batch: 750/1500 | Loss: 0.7910 | Acc: 69.32% | Time: 18.61s
2025-05-30 00:36:30,783 - trainer - INFO - Epoch: 2 | Batch: 800/1500 | Loss: 0.7903 | Acc: 69.33% | Time: 19.07s
2025-05-30 00:36:31,284 - trainer - INFO - Epoch: 2 | Batch: 850/1500 | Loss: 0.7890 | Acc: 69.39% | Time: 19.57s
2025-05-30 00:36:31,779 - trainer - INFO - Epoch: 2 | Batch: 900/1500 | Loss: 0.7879 | Acc: 69.40% | Time: 20.06s
2025-05-30 00:36:32,281 - trainer - INFO - Epoch: 2 | Batch: 950/1500 | Loss: 0.7852 | Acc: 69.44% | Time: 20.56s
2025-05-30 00:36:32,773 - trainer - INFO - Epoch: 2 | Batch: 1000/1500 | Loss: 0.7841 | Acc: 69.48% | Time: 21.06s
2025-05-30 00:36:33,227 - trainer - INFO - Epoch: 2 | Batch: 1050/1500 | Loss: 0.7831 | Acc: 69.50% | Time: 21.51s
2025-05-30 00:36:33,696 - trainer - INFO - Epoch: 2 | Batch: 1100/1500 | Loss: 0.7818 | Acc: 69.57% | Time: 21.98s
2025-05-30 00:36:34,138 - trainer - INFO - Epoch: 2 | Batch: 1150/1500 | Loss: 0.7813 | Acc: 69.57% | Time: 22.42s
2025-05-30 00:36:34,635 - trainer - INFO - Epoch: 2 | Batch: 1200/1500 | Loss: 0.7808 | Acc: 69.58% | Time: 22.92s
2025-05-30 00:36:35,142 - trainer - INFO - Epoch: 2 | Batch: 1250/1500 | Loss: 0.7799 | Acc: 69.56% | Time: 23.43s
2025-05-30 00:36:35,656 - trainer - INFO - Epoch: 2 | Batch: 1300/1500 | Loss: 0.7797 | Acc: 69.57% | Time: 23.94s
2025-05-30 00:36:36,101 - trainer - INFO - Epoch: 2 | Batch: 1350/1500 | Loss: 0.7791 | Acc: 69.60% | Time: 24.39s
2025-05-30 00:36:36,589 - trainer - INFO - Epoch: 2 | Batch: 1400/1500 | Loss: 0.7785 | Acc: 69.60% | Time: 24.87s
2025-05-30 00:36:37,057 - trainer - INFO - Epoch: 2 | Batch: 1450/1500 | Loss: 0.7780 | Acc: 69.62% | Time: 25.34s
2025-05-30 00:36:37,532 - trainer - INFO - Epoch: 2 | Batch: 1500/1500 | Loss: 0.7773 | Acc: 69.67% | Time: 25.82s
2025-05-30 00:36:51,528 - trainer - INFO - 验证 | Loss: 0.6947 | Acc: 72.11%
2025-05-30 00:36:51,537 - trainer - INFO - 最佳模型已保存，epoch 2，验证损失: 0.6947
2025-05-30 00:36:51,537 - trainer - INFO - 
Epoch 3/8
2025-05-30 00:37:04,316 - trainer - INFO - Epoch: 3 | Batch: 50/1500 | Loss: 0.7464 | Acc: 70.66% | Time: 12.78s
2025-05-30 00:37:04,786 - trainer - INFO - Epoch: 3 | Batch: 100/1500 | Loss: 0.7444 | Acc: 70.70% | Time: 13.25s
2025-05-30 00:37:05,253 - trainer - INFO - Epoch: 3 | Batch: 150/1500 | Loss: 0.7544 | Acc: 70.45% | Time: 13.72s
2025-05-30 00:37:05,722 - trainer - INFO - Epoch: 3 | Batch: 200/1500 | Loss: 0.7604 | Acc: 70.28% | Time: 14.18s
2025-05-30 00:37:06,174 - trainer - INFO - Epoch: 3 | Batch: 250/1500 | Loss: 0.7555 | Acc: 70.35% | Time: 14.64s
2025-05-30 00:37:06,641 - trainer - INFO - Epoch: 3 | Batch: 300/1500 | Loss: 0.7571 | Acc: 70.28% | Time: 15.10s
2025-05-30 00:37:07,109 - trainer - INFO - Epoch: 3 | Batch: 350/1500 | Loss: 0.7549 | Acc: 70.37% | Time: 15.57s
2025-05-30 00:37:07,570 - trainer - INFO - Epoch: 3 | Batch: 400/1500 | Loss: 0.7542 | Acc: 70.35% | Time: 16.03s
2025-05-30 00:37:08,037 - trainer - INFO - Epoch: 3 | Batch: 450/1500 | Loss: 0.7528 | Acc: 70.43% | Time: 16.50s
2025-05-30 00:37:08,504 - trainer - INFO - Epoch: 3 | Batch: 500/1500 | Loss: 0.7527 | Acc: 70.38% | Time: 16.97s
2025-05-30 00:37:08,954 - trainer - INFO - Epoch: 3 | Batch: 550/1500 | Loss: 0.7525 | Acc: 70.37% | Time: 17.42s
2025-05-30 00:37:09,420 - trainer - INFO - Epoch: 3 | Batch: 600/1500 | Loss: 0.7536 | Acc: 70.40% | Time: 17.88s
2025-05-30 00:37:09,884 - trainer - INFO - Epoch: 3 | Batch: 650/1500 | Loss: 0.7538 | Acc: 70.37% | Time: 18.35s
2025-05-30 00:37:10,353 - trainer - INFO - Epoch: 3 | Batch: 700/1500 | Loss: 0.7532 | Acc: 70.44% | Time: 18.82s
2025-05-30 00:37:10,819 - trainer - INFO - Epoch: 3 | Batch: 750/1500 | Loss: 0.7512 | Acc: 70.57% | Time: 19.28s
2025-05-30 00:37:11,282 - trainer - INFO - Epoch: 3 | Batch: 800/1500 | Loss: 0.7511 | Acc: 70.56% | Time: 19.75s
2025-05-30 00:37:11,745 - trainer - INFO - Epoch: 3 | Batch: 850/1500 | Loss: 0.7507 | Acc: 70.57% | Time: 20.21s
2025-05-30 00:37:12,209 - trainer - INFO - Epoch: 3 | Batch: 900/1500 | Loss: 0.7503 | Acc: 70.56% | Time: 20.67s
2025-05-30 00:37:12,648 - trainer - INFO - Epoch: 3 | Batch: 950/1500 | Loss: 0.7503 | Acc: 70.57% | Time: 21.11s
2025-05-30 00:37:13,087 - trainer - INFO - Epoch: 3 | Batch: 1000/1500 | Loss: 0.7500 | Acc: 70.62% | Time: 21.55s
2025-05-30 00:37:13,524 - trainer - INFO - Epoch: 3 | Batch: 1050/1500 | Loss: 0.7501 | Acc: 70.67% | Time: 21.99s
2025-05-30 00:37:13,961 - trainer - INFO - Epoch: 3 | Batch: 1100/1500 | Loss: 0.7503 | Acc: 70.68% | Time: 22.42s
2025-05-30 00:37:14,399 - trainer - INFO - Epoch: 3 | Batch: 1150/1500 | Loss: 0.7499 | Acc: 70.68% | Time: 22.86s
2025-05-30 00:37:14,843 - trainer - INFO - Epoch: 3 | Batch: 1200/1500 | Loss: 0.7496 | Acc: 70.72% | Time: 23.31s
2025-05-30 00:37:15,300 - trainer - INFO - Epoch: 3 | Batch: 1250/1500 | Loss: 0.7487 | Acc: 70.75% | Time: 23.76s
2025-05-30 00:37:15,739 - trainer - INFO - Epoch: 3 | Batch: 1300/1500 | Loss: 0.7485 | Acc: 70.77% | Time: 24.20s
2025-05-30 00:37:16,177 - trainer - INFO - Epoch: 3 | Batch: 1350/1500 | Loss: 0.7475 | Acc: 70.77% | Time: 24.64s
2025-05-30 00:37:16,629 - trainer - INFO - Epoch: 3 | Batch: 1400/1500 | Loss: 0.7470 | Acc: 70.77% | Time: 25.09s
2025-05-30 00:37:17,078 - trainer - INFO - Epoch: 3 | Batch: 1450/1500 | Loss: 0.7465 | Acc: 70.80% | Time: 25.54s
2025-05-30 00:37:17,525 - trainer - INFO - Epoch: 3 | Batch: 1500/1500 | Loss: 0.7459 | Acc: 70.83% | Time: 25.99s
2025-05-30 00:37:31,450 - trainer - INFO - 验证 | Loss: 0.7372 | Acc: 69.81%
2025-05-30 00:37:31,450 - trainer - INFO - 验证损失未改善。耐心计数: 1/10
2025-05-30 00:37:31,452 - trainer - INFO - 
Epoch 4/8
2025-05-30 00:37:43,859 - trainer - INFO - Epoch: 4 | Batch: 50/1500 | Loss: 0.7214 | Acc: 71.89% | Time: 12.41s
2025-05-30 00:37:44,304 - trainer - INFO - Epoch: 4 | Batch: 100/1500 | Loss: 0.7320 | Acc: 71.30% | Time: 12.85s
2025-05-30 00:37:44,748 - trainer - INFO - Epoch: 4 | Batch: 150/1500 | Loss: 0.7370 | Acc: 70.89% | Time: 13.30s
2025-05-30 00:37:45,189 - trainer - INFO - Epoch: 4 | Batch: 200/1500 | Loss: 0.7400 | Acc: 70.94% | Time: 13.74s
2025-05-30 00:37:45,634 - trainer - INFO - Epoch: 4 | Batch: 250/1500 | Loss: 0.7398 | Acc: 70.98% | Time: 14.18s
2025-05-30 00:37:46,076 - trainer - INFO - Epoch: 4 | Batch: 300/1500 | Loss: 0.7414 | Acc: 70.87% | Time: 14.62s
2025-05-30 00:37:46,532 - trainer - INFO - Epoch: 4 | Batch: 350/1500 | Loss: 0.7382 | Acc: 71.05% | Time: 15.08s
2025-05-30 00:37:46,979 - trainer - INFO - Epoch: 4 | Batch: 400/1500 | Loss: 0.7358 | Acc: 71.12% | Time: 15.53s
2025-05-30 00:37:47,424 - trainer - INFO - Epoch: 4 | Batch: 450/1500 | Loss: 0.7355 | Acc: 71.07% | Time: 15.97s
2025-05-30 00:37:47,869 - trainer - INFO - Epoch: 4 | Batch: 500/1500 | Loss: 0.7345 | Acc: 71.10% | Time: 16.42s
2025-05-30 00:37:48,311 - trainer - INFO - Epoch: 4 | Batch: 550/1500 | Loss: 0.7341 | Acc: 71.17% | Time: 16.86s
2025-05-30 00:37:48,755 - trainer - INFO - Epoch: 4 | Batch: 600/1500 | Loss: 0.7333 | Acc: 71.20% | Time: 17.30s
2025-05-30 00:37:49,203 - trainer - INFO - Epoch: 4 | Batch: 650/1500 | Loss: 0.7319 | Acc: 71.32% | Time: 17.75s
2025-05-30 00:37:49,647 - trainer - INFO - Epoch: 4 | Batch: 700/1500 | Loss: 0.7316 | Acc: 71.32% | Time: 18.19s
2025-05-30 00:37:50,086 - trainer - INFO - Epoch: 4 | Batch: 750/1500 | Loss: 0.7314 | Acc: 71.32% | Time: 18.63s
2025-05-30 00:37:50,528 - trainer - INFO - Epoch: 4 | Batch: 800/1500 | Loss: 0.7315 | Acc: 71.31% | Time: 19.08s
2025-05-30 00:37:50,968 - trainer - INFO - Epoch: 4 | Batch: 850/1500 | Loss: 0.7309 | Acc: 71.31% | Time: 19.52s
2025-05-30 00:37:51,407 - trainer - INFO - Epoch: 4 | Batch: 900/1500 | Loss: 0.7323 | Acc: 71.27% | Time: 19.95s
2025-05-30 00:37:51,848 - trainer - INFO - Epoch: 4 | Batch: 950/1500 | Loss: 0.7318 | Acc: 71.28% | Time: 20.40s
2025-05-30 00:37:52,288 - trainer - INFO - Epoch: 4 | Batch: 1000/1500 | Loss: 0.7317 | Acc: 71.29% | Time: 20.84s
2025-05-30 00:37:52,727 - trainer - INFO - Epoch: 4 | Batch: 1050/1500 | Loss: 0.7324 | Acc: 71.27% | Time: 21.27s
2025-05-30 00:37:53,167 - trainer - INFO - Epoch: 4 | Batch: 1100/1500 | Loss: 0.7311 | Acc: 71.31% | Time: 21.71s
2025-05-30 00:37:53,608 - trainer - INFO - Epoch: 4 | Batch: 1150/1500 | Loss: 0.7312 | Acc: 71.34% | Time: 22.16s
2025-05-30 00:37:54,048 - trainer - INFO - Epoch: 4 | Batch: 1200/1500 | Loss: 0.7310 | Acc: 71.35% | Time: 22.60s
2025-05-30 00:37:54,485 - trainer - INFO - Epoch: 4 | Batch: 1250/1500 | Loss: 0.7308 | Acc: 71.33% | Time: 23.03s
2025-05-30 00:37:54,924 - trainer - INFO - Epoch: 4 | Batch: 1300/1500 | Loss: 0.7311 | Acc: 71.34% | Time: 23.47s
2025-05-30 00:37:55,359 - trainer - INFO - Epoch: 4 | Batch: 1350/1500 | Loss: 0.7318 | Acc: 71.32% | Time: 23.91s
2025-05-30 00:37:55,795 - trainer - INFO - Epoch: 4 | Batch: 1400/1500 | Loss: 0.7319 | Acc: 71.31% | Time: 24.34s
2025-05-30 00:37:56,230 - trainer - INFO - Epoch: 4 | Batch: 1450/1500 | Loss: 0.7326 | Acc: 71.29% | Time: 24.78s
2025-05-30 00:37:56,669 - trainer - INFO - Epoch: 4 | Batch: 1500/1500 | Loss: 0.7322 | Acc: 71.30% | Time: 25.22s
2025-05-30 00:38:10,269 - trainer - INFO - 验证 | Loss: 0.6685 | Acc: 72.79%
2025-05-30 00:38:10,277 - trainer - INFO - 最佳模型已保存，epoch 4，验证损失: 0.6685
2025-05-30 00:38:10,277 - trainer - INFO - 
Epoch 5/8
2025-05-30 00:38:22,036 - trainer - INFO - Epoch: 5 | Batch: 50/1500 | Loss: 0.7074 | Acc: 72.09% | Time: 11.76s
2025-05-30 00:38:22,472 - trainer - INFO - Epoch: 5 | Batch: 100/1500 | Loss: 0.7185 | Acc: 71.77% | Time: 12.20s
2025-05-30 00:38:22,909 - trainer - INFO - Epoch: 5 | Batch: 150/1500 | Loss: 0.7238 | Acc: 71.62% | Time: 12.63s
2025-05-30 00:38:23,347 - trainer - INFO - Epoch: 5 | Batch: 200/1500 | Loss: 0.7272 | Acc: 71.42% | Time: 13.07s
2025-05-30 00:38:23,785 - trainer - INFO - Epoch: 5 | Batch: 250/1500 | Loss: 0.7284 | Acc: 71.38% | Time: 13.51s
2025-05-30 00:38:24,223 - trainer - INFO - Epoch: 5 | Batch: 300/1500 | Loss: 0.7263 | Acc: 71.49% | Time: 13.95s
2025-05-30 00:38:24,660 - trainer - INFO - Epoch: 5 | Batch: 350/1500 | Loss: 0.7274 | Acc: 71.55% | Time: 14.38s
2025-05-30 00:38:25,098 - trainer - INFO - Epoch: 5 | Batch: 400/1500 | Loss: 0.7271 | Acc: 71.51% | Time: 14.82s
2025-05-30 00:38:25,534 - trainer - INFO - Epoch: 5 | Batch: 450/1500 | Loss: 0.7272 | Acc: 71.49% | Time: 15.26s
2025-05-30 00:38:25,971 - trainer - INFO - Epoch: 5 | Batch: 500/1500 | Loss: 0.7277 | Acc: 71.47% | Time: 15.69s
2025-05-30 00:38:26,409 - trainer - INFO - Epoch: 5 | Batch: 550/1500 | Loss: 0.7251 | Acc: 71.53% | Time: 16.13s
2025-05-30 00:38:26,846 - trainer - INFO - Epoch: 5 | Batch: 600/1500 | Loss: 0.7254 | Acc: 71.55% | Time: 16.57s
2025-05-30 00:38:27,284 - trainer - INFO - Epoch: 5 | Batch: 650/1500 | Loss: 0.7250 | Acc: 71.59% | Time: 17.01s
2025-05-30 00:38:27,722 - trainer - INFO - Epoch: 5 | Batch: 700/1500 | Loss: 0.7267 | Acc: 71.56% | Time: 17.45s
2025-05-30 00:38:28,158 - trainer - INFO - Epoch: 5 | Batch: 750/1500 | Loss: 0.7274 | Acc: 71.53% | Time: 17.88s
2025-05-30 00:38:28,597 - trainer - INFO - Epoch: 5 | Batch: 800/1500 | Loss: 0.7276 | Acc: 71.50% | Time: 18.32s
2025-05-30 00:38:29,033 - trainer - INFO - Epoch: 5 | Batch: 850/1500 | Loss: 0.7258 | Acc: 71.60% | Time: 18.76s
2025-05-30 00:38:29,470 - trainer - INFO - Epoch: 5 | Batch: 900/1500 | Loss: 0.7244 | Acc: 71.65% | Time: 19.19s
2025-05-30 00:38:29,907 - trainer - INFO - Epoch: 5 | Batch: 950/1500 | Loss: 0.7234 | Acc: 71.70% | Time: 19.63s
2025-05-30 00:38:30,344 - trainer - INFO - Epoch: 5 | Batch: 1000/1500 | Loss: 0.7232 | Acc: 71.68% | Time: 20.07s
2025-05-30 00:38:30,782 - trainer - INFO - Epoch: 5 | Batch: 1050/1500 | Loss: 0.7236 | Acc: 71.68% | Time: 20.51s
2025-05-30 00:38:31,220 - trainer - INFO - Epoch: 5 | Batch: 1100/1500 | Loss: 0.7233 | Acc: 71.69% | Time: 20.94s
2025-05-30 00:38:31,656 - trainer - INFO - Epoch: 5 | Batch: 1150/1500 | Loss: 0.7238 | Acc: 71.65% | Time: 21.38s
2025-05-30 00:38:32,093 - trainer - INFO - Epoch: 5 | Batch: 1200/1500 | Loss: 0.7238 | Acc: 71.63% | Time: 21.82s
2025-05-30 00:38:32,531 - trainer - INFO - Epoch: 5 | Batch: 1250/1500 | Loss: 0.7240 | Acc: 71.63% | Time: 22.25s
2025-05-30 00:38:32,966 - trainer - INFO - Epoch: 5 | Batch: 1300/1500 | Loss: 0.7242 | Acc: 71.62% | Time: 22.69s
2025-05-30 00:38:33,404 - trainer - INFO - Epoch: 5 | Batch: 1350/1500 | Loss: 0.7242 | Acc: 71.62% | Time: 23.13s
2025-05-30 00:38:33,843 - trainer - INFO - Epoch: 5 | Batch: 1400/1500 | Loss: 0.7238 | Acc: 71.65% | Time: 23.57s
2025-05-30 00:38:34,280 - trainer - INFO - Epoch: 5 | Batch: 1450/1500 | Loss: 0.7236 | Acc: 71.66% | Time: 24.00s
2025-05-30 00:38:34,722 - trainer - INFO - Epoch: 5 | Batch: 1500/1500 | Loss: 0.7236 | Acc: 71.68% | Time: 24.45s
2025-05-30 00:38:49,773 - trainer - INFO - 验证 | Loss: 0.6607 | Acc: 73.08%
2025-05-30 00:38:49,781 - trainer - INFO - 最佳模型已保存，epoch 5，验证损失: 0.6607
2025-05-30 00:38:49,791 - trainer - INFO - 
Epoch 6/8
2025-05-30 00:39:02,836 - trainer - INFO - Epoch: 6 | Batch: 50/1500 | Loss: 0.7026 | Acc: 72.47% | Time: 13.04s
2025-05-30 00:39:03,291 - trainer - INFO - Epoch: 6 | Batch: 100/1500 | Loss: 0.7101 | Acc: 72.06% | Time: 13.50s
2025-05-30 00:39:03,730 - trainer - INFO - Epoch: 6 | Batch: 150/1500 | Loss: 0.7132 | Acc: 72.05% | Time: 13.94s
2025-05-30 00:39:04,169 - trainer - INFO - Epoch: 6 | Batch: 200/1500 | Loss: 0.7185 | Acc: 71.91% | Time: 14.38s
2025-05-30 00:39:04,620 - trainer - INFO - Epoch: 6 | Batch: 250/1500 | Loss: 0.7174 | Acc: 71.82% | Time: 14.83s
2025-05-30 00:39:05,070 - trainer - INFO - Epoch: 6 | Batch: 300/1500 | Loss: 0.7196 | Acc: 71.78% | Time: 15.28s
2025-05-30 00:39:05,523 - trainer - INFO - Epoch: 6 | Batch: 350/1500 | Loss: 0.7183 | Acc: 71.92% | Time: 15.73s
2025-05-30 00:39:05,990 - trainer - INFO - Epoch: 6 | Batch: 400/1500 | Loss: 0.7189 | Acc: 71.83% | Time: 16.20s
2025-05-30 00:39:06,450 - trainer - INFO - Epoch: 6 | Batch: 450/1500 | Loss: 0.7186 | Acc: 71.81% | Time: 16.66s
2025-05-30 00:39:06,900 - trainer - INFO - Epoch: 6 | Batch: 500/1500 | Loss: 0.7179 | Acc: 71.80% | Time: 17.11s
2025-05-30 00:39:07,340 - trainer - INFO - Epoch: 6 | Batch: 550/1500 | Loss: 0.7183 | Acc: 71.81% | Time: 17.55s
2025-05-30 00:39:07,795 - trainer - INFO - Epoch: 6 | Batch: 600/1500 | Loss: 0.7175 | Acc: 71.87% | Time: 18.00s
2025-05-30 00:39:08,235 - trainer - INFO - Epoch: 6 | Batch: 650/1500 | Loss: 0.7175 | Acc: 71.87% | Time: 18.44s
2025-05-30 00:39:08,685 - trainer - INFO - Epoch: 6 | Batch: 700/1500 | Loss: 0.7179 | Acc: 71.86% | Time: 18.89s
2025-05-30 00:39:09,125 - trainer - INFO - Epoch: 6 | Batch: 750/1500 | Loss: 0.7182 | Acc: 71.86% | Time: 19.33s
2025-05-30 00:39:09,563 - trainer - INFO - Epoch: 6 | Batch: 800/1500 | Loss: 0.7175 | Acc: 71.87% | Time: 19.77s
2025-05-30 00:39:10,007 - trainer - INFO - Epoch: 6 | Batch: 850/1500 | Loss: 0.7176 | Acc: 71.86% | Time: 20.22s
2025-05-30 00:39:10,449 - trainer - INFO - Epoch: 6 | Batch: 900/1500 | Loss: 0.7178 | Acc: 71.81% | Time: 20.66s
2025-05-30 00:39:10,890 - trainer - INFO - Epoch: 6 | Batch: 950/1500 | Loss: 0.7180 | Acc: 71.77% | Time: 21.10s
2025-05-30 00:39:11,328 - trainer - INFO - Epoch: 6 | Batch: 1000/1500 | Loss: 0.7178 | Acc: 71.78% | Time: 21.54s
2025-05-30 00:39:11,766 - trainer - INFO - Epoch: 6 | Batch: 1050/1500 | Loss: 0.7173 | Acc: 71.82% | Time: 21.98s
2025-05-30 00:39:12,204 - trainer - INFO - Epoch: 6 | Batch: 1100/1500 | Loss: 0.7172 | Acc: 71.82% | Time: 22.41s
2025-05-30 00:39:12,664 - trainer - INFO - Epoch: 6 | Batch: 1150/1500 | Loss: 0.7171 | Acc: 71.83% | Time: 22.87s
2025-05-30 00:39:13,117 - trainer - INFO - Epoch: 6 | Batch: 1200/1500 | Loss: 0.7171 | Acc: 71.84% | Time: 23.33s
2025-05-30 00:39:13,580 - trainer - INFO - Epoch: 6 | Batch: 1250/1500 | Loss: 0.7176 | Acc: 71.84% | Time: 23.79s
2025-05-30 00:39:14,034 - trainer - INFO - Epoch: 6 | Batch: 1300/1500 | Loss: 0.7176 | Acc: 71.84% | Time: 24.24s
2025-05-30 00:39:14,497 - trainer - INFO - Epoch: 6 | Batch: 1350/1500 | Loss: 0.7172 | Acc: 71.84% | Time: 24.71s
2025-05-30 00:39:14,944 - trainer - INFO - Epoch: 6 | Batch: 1400/1500 | Loss: 0.7172 | Acc: 71.83% | Time: 25.15s
2025-05-30 00:39:15,383 - trainer - INFO - Epoch: 6 | Batch: 1450/1500 | Loss: 0.7166 | Acc: 71.86% | Time: 25.59s
2025-05-30 00:39:15,825 - trainer - INFO - Epoch: 6 | Batch: 1500/1500 | Loss: 0.7165 | Acc: 71.86% | Time: 26.03s
2025-05-30 00:39:30,341 - trainer - INFO - 验证 | Loss: 0.6747 | Acc: 72.31%
2025-05-30 00:39:30,341 - trainer - INFO - 验证损失未改善。耐心计数: 1/10
2025-05-30 00:39:30,341 - trainer - INFO - 
Epoch 7/8
2025-05-30 00:39:44,244 - trainer - INFO - Epoch: 7 | Batch: 50/1500 | Loss: 0.7071 | Acc: 72.83% | Time: 13.90s
2025-05-30 00:39:44,690 - trainer - INFO - Epoch: 7 | Batch: 100/1500 | Loss: 0.7190 | Acc: 72.27% | Time: 14.35s
2025-05-30 00:39:45,165 - trainer - INFO - Epoch: 7 | Batch: 150/1500 | Loss: 0.7150 | Acc: 72.22% | Time: 14.82s
2025-05-30 00:39:45,629 - trainer - INFO - Epoch: 7 | Batch: 200/1500 | Loss: 0.7190 | Acc: 71.89% | Time: 15.29s
2025-05-30 00:39:46,074 - trainer - INFO - Epoch: 7 | Batch: 250/1500 | Loss: 0.7172 | Acc: 71.86% | Time: 15.73s
2025-05-30 00:39:46,517 - trainer - INFO - Epoch: 7 | Batch: 300/1500 | Loss: 0.7186 | Acc: 71.67% | Time: 16.18s
2025-05-30 00:39:46,960 - trainer - INFO - Epoch: 7 | Batch: 350/1500 | Loss: 0.7156 | Acc: 71.78% | Time: 16.62s
2025-05-30 00:39:47,401 - trainer - INFO - Epoch: 7 | Batch: 400/1500 | Loss: 0.7151 | Acc: 71.84% | Time: 17.06s
2025-05-30 00:39:47,853 - trainer - INFO - Epoch: 7 | Batch: 450/1500 | Loss: 0.7147 | Acc: 71.83% | Time: 17.51s
2025-05-30 00:39:48,296 - trainer - INFO - Epoch: 7 | Batch: 500/1500 | Loss: 0.7130 | Acc: 71.94% | Time: 17.95s
2025-05-30 00:39:48,738 - trainer - INFO - Epoch: 7 | Batch: 550/1500 | Loss: 0.7121 | Acc: 71.95% | Time: 18.40s
2025-05-30 00:39:49,216 - trainer - INFO - Epoch: 7 | Batch: 600/1500 | Loss: 0.7132 | Acc: 71.88% | Time: 18.88s
2025-05-30 00:39:49,665 - trainer - INFO - Epoch: 7 | Batch: 650/1500 | Loss: 0.7144 | Acc: 71.82% | Time: 19.32s
2025-05-30 00:39:50,102 - trainer - INFO - Epoch: 7 | Batch: 700/1500 | Loss: 0.7152 | Acc: 71.76% | Time: 19.76s
2025-05-30 00:39:50,548 - trainer - INFO - Epoch: 7 | Batch: 750/1500 | Loss: 0.7136 | Acc: 71.84% | Time: 20.21s
2025-05-30 00:39:50,986 - trainer - INFO - Epoch: 7 | Batch: 800/1500 | Loss: 0.7150 | Acc: 71.83% | Time: 20.65s
2025-05-30 00:39:51,427 - trainer - INFO - Epoch: 7 | Batch: 850/1500 | Loss: 0.7139 | Acc: 71.91% | Time: 21.09s
2025-05-30 00:39:51,867 - trainer - INFO - Epoch: 7 | Batch: 900/1500 | Loss: 0.7144 | Acc: 71.91% | Time: 21.53s
2025-05-30 00:39:52,307 - trainer - INFO - Epoch: 7 | Batch: 950/1500 | Loss: 0.7143 | Acc: 71.89% | Time: 21.97s
2025-05-30 00:39:52,764 - trainer - INFO - Epoch: 7 | Batch: 1000/1500 | Loss: 0.7140 | Acc: 71.89% | Time: 22.42s
2025-05-30 00:39:53,216 - trainer - INFO - Epoch: 7 | Batch: 1050/1500 | Loss: 0.7141 | Acc: 71.87% | Time: 22.88s
2025-05-30 00:39:53,671 - trainer - INFO - Epoch: 7 | Batch: 1100/1500 | Loss: 0.7139 | Acc: 71.86% | Time: 23.33s
2025-05-30 00:39:54,108 - trainer - INFO - Epoch: 7 | Batch: 1150/1500 | Loss: 0.7136 | Acc: 71.88% | Time: 23.77s
2025-05-30 00:39:54,558 - trainer - INFO - Epoch: 7 | Batch: 1200/1500 | Loss: 0.7139 | Acc: 71.88% | Time: 24.22s
2025-05-30 00:39:55,000 - trainer - INFO - Epoch: 7 | Batch: 1250/1500 | Loss: 0.7140 | Acc: 71.89% | Time: 24.66s
2025-05-30 00:39:55,448 - trainer - INFO - Epoch: 7 | Batch: 1300/1500 | Loss: 0.7152 | Acc: 71.82% | Time: 25.11s
2025-05-30 00:39:55,892 - trainer - INFO - Epoch: 7 | Batch: 1350/1500 | Loss: 0.7149 | Acc: 71.86% | Time: 25.55s
2025-05-30 00:39:56,353 - trainer - INFO - Epoch: 7 | Batch: 1400/1500 | Loss: 0.7146 | Acc: 71.87% | Time: 26.01s
2025-05-30 00:39:56,808 - trainer - INFO - Epoch: 7 | Batch: 1450/1500 | Loss: 0.7144 | Acc: 71.88% | Time: 26.47s
2025-05-30 00:39:57,259 - trainer - INFO - Epoch: 7 | Batch: 1500/1500 | Loss: 0.7142 | Acc: 71.88% | Time: 26.92s
2025-05-30 00:40:12,169 - trainer - INFO - 验证 | Loss: 0.6754 | Acc: 72.33%
2025-05-30 00:40:12,169 - trainer - INFO - 验证损失未改善。耐心计数: 2/10
2025-05-30 00:40:12,169 - trainer - INFO - 
Epoch 8/8
2025-05-30 00:40:24,635 - trainer - INFO - Epoch: 8 | Batch: 50/1500 | Loss: 0.7193 | Acc: 72.16% | Time: 12.47s
2025-05-30 00:40:25,084 - trainer - INFO - Epoch: 8 | Batch: 100/1500 | Loss: 0.7223 | Acc: 71.95% | Time: 12.91s
2025-05-30 00:40:25,528 - trainer - INFO - Epoch: 8 | Batch: 150/1500 | Loss: 0.7217 | Acc: 71.88% | Time: 13.36s
2025-05-30 00:40:25,983 - trainer - INFO - Epoch: 8 | Batch: 200/1500 | Loss: 0.7128 | Acc: 72.18% | Time: 13.81s
2025-05-30 00:40:26,422 - trainer - INFO - Epoch: 8 | Batch: 250/1500 | Loss: 0.7182 | Acc: 72.00% | Time: 14.25s
2025-05-30 00:40:26,886 - trainer - INFO - Epoch: 8 | Batch: 300/1500 | Loss: 0.7206 | Acc: 71.86% | Time: 14.72s
2025-05-30 00:40:27,351 - trainer - INFO - Epoch: 8 | Batch: 350/1500 | Loss: 0.7179 | Acc: 71.96% | Time: 15.18s
2025-05-30 00:40:27,811 - trainer - INFO - Epoch: 8 | Batch: 400/1500 | Loss: 0.7183 | Acc: 71.92% | Time: 15.64s
2025-05-30 00:40:28,257 - trainer - INFO - Epoch: 8 | Batch: 450/1500 | Loss: 0.7173 | Acc: 71.95% | Time: 16.09s
2025-05-30 00:40:28,713 - trainer - INFO - Epoch: 8 | Batch: 500/1500 | Loss: 0.7182 | Acc: 71.97% | Time: 16.54s
2025-05-30 00:40:29,178 - trainer - INFO - Epoch: 8 | Batch: 550/1500 | Loss: 0.7161 | Acc: 72.01% | Time: 17.01s
2025-05-30 00:40:29,645 - trainer - INFO - Epoch: 8 | Batch: 600/1500 | Loss: 0.7151 | Acc: 72.03% | Time: 17.48s
2025-05-30 00:40:30,109 - trainer - INFO - Epoch: 8 | Batch: 650/1500 | Loss: 0.7131 | Acc: 72.05% | Time: 17.94s
2025-05-30 00:40:30,572 - trainer - INFO - Epoch: 8 | Batch: 700/1500 | Loss: 0.7130 | Acc: 72.04% | Time: 18.40s
2025-05-30 00:40:31,047 - trainer - INFO - Epoch: 8 | Batch: 750/1500 | Loss: 0.7123 | Acc: 72.07% | Time: 18.88s
2025-05-30 00:40:31,509 - trainer - INFO - Epoch: 8 | Batch: 800/1500 | Loss: 0.7113 | Acc: 72.14% | Time: 19.34s
2025-05-30 00:40:31,977 - trainer - INFO - Epoch: 8 | Batch: 850/1500 | Loss: 0.7118 | Acc: 72.13% | Time: 19.81s
2025-05-30 00:40:32,440 - trainer - INFO - Epoch: 8 | Batch: 900/1500 | Loss: 0.7117 | Acc: 72.14% | Time: 20.27s
2025-05-30 00:40:32,902 - trainer - INFO - Epoch: 8 | Batch: 950/1500 | Loss: 0.7117 | Acc: 72.15% | Time: 20.73s
2025-05-30 00:40:33,363 - trainer - INFO - Epoch: 8 | Batch: 1000/1500 | Loss: 0.7121 | Acc: 72.11% | Time: 21.19s
2025-05-30 00:40:33,821 - trainer - INFO - Epoch: 8 | Batch: 1050/1500 | Loss: 0.7132 | Acc: 72.11% | Time: 21.65s
2025-05-30 00:40:34,261 - trainer - INFO - Epoch: 8 | Batch: 1100/1500 | Loss: 0.7126 | Acc: 72.13% | Time: 22.09s
2025-05-30 00:40:34,699 - trainer - INFO - Epoch: 8 | Batch: 1150/1500 | Loss: 0.7129 | Acc: 72.12% | Time: 22.53s
2025-05-30 00:40:35,137 - trainer - INFO - Epoch: 8 | Batch: 1200/1500 | Loss: 0.7127 | Acc: 72.14% | Time: 22.97s
2025-05-30 00:40:35,576 - trainer - INFO - Epoch: 8 | Batch: 1250/1500 | Loss: 0.7127 | Acc: 72.11% | Time: 23.41s
2025-05-30 00:40:36,016 - trainer - INFO - Epoch: 8 | Batch: 1300/1500 | Loss: 0.7125 | Acc: 72.10% | Time: 23.85s
2025-05-30 00:40:36,456 - trainer - INFO - Epoch: 8 | Batch: 1350/1500 | Loss: 0.7123 | Acc: 72.09% | Time: 24.29s
2025-05-30 00:40:36,894 - trainer - INFO - Epoch: 8 | Batch: 1400/1500 | Loss: 0.7115 | Acc: 72.12% | Time: 24.73s
2025-05-30 00:40:37,331 - trainer - INFO - Epoch: 8 | Batch: 1450/1500 | Loss: 0.7108 | Acc: 72.13% | Time: 25.16s
2025-05-30 00:40:37,775 - trainer - INFO - Epoch: 8 | Batch: 1500/1500 | Loss: 0.7109 | Acc: 72.14% | Time: 25.61s
2025-05-30 00:40:51,852 - trainer - INFO - 验证 | Loss: 0.6668 | Acc: 72.98%
2025-05-30 00:40:51,852 - trainer - INFO - 验证损失未改善。耐心计数: 3/10
2025-05-30 00:40:51,852 - trainer - INFO - 训练完成。最佳验证损失: 0.6607，在epoch 5。
2025-05-30 00:40:52,224 - utils - INFO - 训练历史图已保存至 ./outputs\training_history.png
2025-05-30 00:40:52,237 - trainer - INFO - 已加载检查点，来自epoch 5，验证损失: 0.6607，验证准确率: 73.08%
2025-05-30 00:40:52,237 - __main__ - INFO - 在验证集上评估LSTM模型...
2025-05-30 00:41:05,605 - utils - INFO - 评估 | Loss: 0.6607 | Acc: 73.08%
2025-05-30 00:41:06,031 - utils - INFO - 混淆矩阵已保存至 ./outputs\confusion_matrix.png
2025-05-30 00:41:06,090 - __main__ - INFO - 分类报告:
              precision    recall  f1-score       support
BENIGN         0.864200  0.992998  0.924133   3999.000000
DNS            0.843387  0.545250  0.662314   4000.000000
LDAP           0.644444  0.761250  0.697994   4000.000000
MSSQL          0.674227  0.921500  0.778705   4000.000000
NTP            0.938141  0.800000  0.863581   4000.000000
NetBIOS        0.872134  0.741750  0.801675   4000.000000
SNMP           0.667281  0.724500  0.694714   4000.000000
SSDP           0.501731  0.362250  0.420732   4000.000000
Syn            0.962728  0.949250  0.955942   4000.000000
TFTP           0.923848  0.967500  0.945170   4000.000000
UDP            0.438536  0.800000  0.566522   4000.000000
UDP-lag        0.708333  0.204000  0.316770   4000.000000
accuracy       0.730849  0.730849  0.730849      0.730849
macro avg      0.753249  0.730854  0.719021  47999.000000
weighted avg   0.753247  0.730849  0.719017  47999.000000
2025-05-30 00:41:19,539 - utils - INFO - ROC曲线已保存至 ./outputs\roc_curves.png
2025-05-30 00:41:19,539 - __main__ - INFO - 导出模型为ONNX格式...
2025-05-30 00:41:19,667 - utils - INFO - 模型已导出为ONNX格式: ./outputs\ddos_detector.onnx
2025-05-30 00:41:19,688 - utils - INFO - ONNX模型验证通过。
2025-05-30 00:41:19,688 - __main__ - INFO - LSTM模型训练和评估完成。结果保存到 ./outputs
2025-05-30 00:41:19,701 - __main__ - INFO - 加载数据集用于SVM训练...
2025-05-30 00:41:19,701 - data - INFO - 加载预处理器从: ./outputs\preprocessor.pkl
2025-05-30 00:41:19,702 - data - INFO - 预处理器已从 ./outputs\preprocessor.pkl 加载，PCA维度: 30
2025-05-30 00:41:19,702 - data - INFO - 预处理器加载成功
2025-05-30 00:41:19,702 - data - INFO - 开始数据处理流水线，模式: 验证
2025-05-30 00:41:19,702 - data - INFO - 开始读取文件: train_dataset.csv
2025-05-30 00:41:19,706 - data - INFO - CSV文件包含 45 个列
2025-05-30 00:41:19,707 - data - INFO - 将读取 45 列: 44 个特征列和 1 个标签列
2025-05-30 00:41:20,141 - data - INFO - 文件 train_dataset.csv 读取完成，shape=(192000, 45)
2025-05-30 00:41:20,144 - data - INFO - 开始数据清洗
2025-05-30 00:41:20,144 - data - INFO - 原始数据形状: (192000, 45)
2025-05-30 00:41:20,346 - data - INFO - 移除重复记录后剩余 191996 条记录
2025-05-30 00:41:20,358 - data - INFO - 处理前缺失值总数: 0
2025-05-30 00:41:20,564 - data - INFO - 处理了 364441 个异常值
2025-05-30 00:41:20,564 - data - INFO - 数据清洗完成，最终形状: (191996, 45)
2025-05-30 00:41:20,564 - data - INFO - 开始特征预处理
2025-05-30 00:41:20,707 - data - INFO - 找到 46 个数值特征
2025-05-30 00:41:20,709 - data - INFO - 验证阶段使用 46 个特征
2025-05-30 00:41:20,922 - data - INFO - PCA降维完成，最终特征维数: 30
2025-05-30 00:41:20,923 - data - INFO - 标签one-hot编码维数: 12
2025-05-30 00:41:20,978 - data - INFO - 最终特征形状: (191996, 30), 标签形状: (191996, 12)
2025-05-30 00:41:20,978 - data - INFO - 类别数量: 12
2025-05-30 00:41:20,978 - data - INFO - 数据处理流水线完成
2025-05-30 00:41:20,987 - data - INFO - 特征数据类型: float64
2025-05-30 00:41:20,987 - data - INFO - 标签数据类型: float64
2025-05-30 00:41:20,998 - data - INFO - 特征形状: torch.Size([191996, 30]), 类型: torch.float32
2025-05-30 00:41:20,998 - data - INFO - 标签形状: torch.Size([191996, 12]), 类型: torch.float32
2025-05-30 00:41:20,998 - data - INFO - 标签类别数: 12
2025-05-30 00:41:20,998 - __main__ - INFO - SVM训练数据集大小: 191996
2025-05-30 00:41:20,998 - __main__ - INFO - 检测到字符串标签，统计各类别数量...
2025-05-30 00:41:21,067 - __main__ - INFO - 标签分布: {'BENIGN': 15999, 'DNS': 16000, 'LDAP': 16000, 'MSSQL': 16000, 'NTP': 15997, 'NetBIOS': 16000, 'SNMP': 16000, 'SSDP': 16000, 'Syn': 16000, 'TFTP': 16000, 'UDP': 16000, 'UDP-lag': 16000}
2025-05-30 00:41:21,067 - __main__ - INFO - 混淆类别对 10 vs 11 对应字符串标签: UDP vs UDP-lag
2025-05-30 00:41:21,067 - __main__ - INFO - 混淆类别对 5 vs 7 对应字符串标签: NetBIOS vs SSDP
2025-05-30 00:41:21,067 - __main__ - INFO - 混淆类别对 2 vs 8 对应字符串标签: LDAP vs Syn
2025-05-30 00:41:21,067 - __main__ - INFO - 混淆类别对 9 vs 10 对应字符串标签: TFTP vs UDP
2025-05-30 00:41:21,067 - __main__ - INFO - 混淆类别对 0 vs 4 对应字符串标签: BENIGN vs NTP
2025-05-30 00:41:21,067 - __main__ - INFO - 混淆类别对 0 vs 9 对应字符串标签: BENIGN vs TFTP
2025-05-30 00:41:21,067 - trainer - INFO - SVM训练器初始化完成，输出目录: ./outputs\svm_models
2025-05-30 00:41:21,067 - __main__ - INFO - 开始训练SVM分类器...
2025-05-30 00:41:21,067 - trainer - INFO - 训练 UDP (10) vs UDP-lag (11) 分类器
2025-05-30 00:41:21,102 - trainer - INFO - 类别 UDP (10) 样本数: 16000
2025-05-30 00:41:21,103 - trainer - INFO - 类别 UDP-lag (11) 样本数: 16000
2025-05-30 00:41:21,116 - trainer - INFO - 开始网格搜索SVM最优参数...
2025-05-30 01:05:31,236 - __main__ - INFO - 使用设备: cuda
2025-05-30 01:05:31,237 - __main__ - INFO - 加载数据集...
2025-05-30 01:05:31,237 - data - INFO - 开始数据处理流水线，模式: 训练
2025-05-30 01:05:31,237 - data - INFO - 开始读取文件: train_dataset.csv
2025-05-30 01:05:31,247 - data - INFO - CSV文件包含 45 个列
2025-05-30 01:05:31,247 - data - INFO - 将读取 45 列: 44 个特征列和 1 个标签列
2025-05-30 01:05:31,775 - data - INFO - 文件 train_dataset.csv 读取完成，shape=(192000, 45)
2025-05-30 01:05:31,778 - data - INFO - 开始数据清洗
2025-05-30 01:05:31,778 - data - INFO - 原始数据形状: (192000, 45)
2025-05-30 01:05:32,018 - data - INFO - 移除重复记录后剩余 191996 条记录
2025-05-30 01:05:32,031 - data - INFO - 处理前缺失值总数: 0
2025-05-30 01:05:32,234 - data - INFO - 处理了 364441 个异常值
2025-05-30 01:05:32,234 - data - INFO - 数据清洗完成，最终形状: (191996, 45)
2025-05-30 01:05:32,234 - data - INFO - 开始特征预处理
2025-05-30 01:05:32,285 - data - INFO - 对特征 ' Protocol' 进行独热编码，生成 3 个新特征
2025-05-30 01:05:32,328 - data - INFO - 标签类别: ['BENIGN', 'DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDP-lag']
2025-05-30 01:05:32,328 - data - INFO - 类别数量: 12
2025-05-30 01:05:32,415 - data - INFO - 找到 46 个数值特征
2025-05-30 01:05:32,579 - data - INFO - 保存了 46 个数值特征的顺序和scaler
2025-05-30 01:05:32,622 - data - INFO - 执行 PCA 降维: 从 46 维降至 30 维
2025-05-30 01:05:33,287 - data - INFO - PCA降维后保留信息量: 99.98%
2025-05-30 01:05:33,316 - data - INFO - PCA降维完成，最终特征维数: 30
2025-05-30 01:05:33,316 - data - INFO - 标签one-hot编码维数: 12
2025-05-30 01:05:33,376 - data - INFO - 最终特征形状: (191996, 30), 标签形状: (191996, 12)
2025-05-30 01:05:33,377 - data - INFO - 类别数量: 12
2025-05-30 01:05:33,377 - data - INFO - 数据处理流水线完成
2025-05-30 01:05:33,383 - data - INFO - 保存预处理器到: ./outputs\preprocessor.pkl
2025-05-30 01:05:33,387 - data - INFO - 预处理器已保存至 ./outputs\preprocessor.pkl
2025-05-30 01:05:33,387 - data - INFO - 预处理器保存成功
2025-05-30 01:05:33,387 - data - INFO - 特征数据类型: float64
2025-05-30 01:05:33,387 - data - INFO - 标签数据类型: float64
2025-05-30 01:05:33,404 - data - INFO - 特征形状: torch.Size([191996, 30]), 类型: torch.float32
2025-05-30 01:05:33,404 - data - INFO - 标签形状: torch.Size([191996, 12]), 类型: torch.float32
2025-05-30 01:05:33,404 - data - INFO - 标签类别数: 12
2025-05-30 01:05:33,405 - __main__ - INFO - 训练数据集大小: 191996
2025-05-30 01:05:33,405 - data - INFO - 加载预处理器从: ./outputs\preprocessor.pkl
2025-05-30 01:05:33,405 - data - INFO - 预处理器已从 ./outputs\preprocessor.pkl 加载，PCA维度: 30
2025-05-30 01:05:33,405 - data - INFO - 预处理器加载成功
2025-05-30 01:05:33,405 - data - INFO - 开始数据处理流水线，模式: 验证
2025-05-30 01:05:33,405 - data - INFO - 开始读取文件: test_dataset.csv
2025-05-30 01:05:33,410 - data - INFO - CSV文件包含 45 个列
2025-05-30 01:05:33,410 - data - INFO - 将读取 45 列: 44 个特征列和 1 个标签列
2025-05-30 01:05:33,523 - data - INFO - 文件 test_dataset.csv 读取完成，shape=(48000, 45)
2025-05-30 01:05:33,524 - data - INFO - 开始数据清洗
2025-05-30 01:05:33,524 - data - INFO - 原始数据形状: (48000, 45)
2025-05-30 01:05:33,560 - data - INFO - 移除重复记录后剩余 47999 条记录
2025-05-30 01:05:33,564 - data - INFO - 处理前缺失值总数: 0
2025-05-30 01:05:33,628 - data - INFO - 处理了 90815 个异常值
2025-05-30 01:05:33,628 - data - INFO - 数据清洗完成，最终形状: (47999, 45)
2025-05-30 01:05:33,629 - data - INFO - 开始特征预处理
2025-05-30 01:05:33,667 - data - INFO - 找到 46 个数值特征
2025-05-30 01:05:33,668 - data - INFO - 验证阶段使用 46 个特征
2025-05-30 01:05:33,727 - data - INFO - PCA降维完成，最终特征维数: 30
2025-05-30 01:05:33,727 - data - INFO - 标签one-hot编码维数: 12
2025-05-30 01:05:33,745 - data - INFO - 最终特征形状: (47999, 30), 标签形状: (47999, 12)
2025-05-30 01:05:33,745 - data - INFO - 类别数量: 12
2025-05-30 01:05:33,745 - data - INFO - 数据处理流水线完成
2025-05-30 01:05:33,748 - data - INFO - 特征数据类型: float64
2025-05-30 01:05:33,748 - data - INFO - 标签数据类型: float64
2025-05-30 01:05:33,752 - data - INFO - 特征形状: torch.Size([47999, 30]), 类型: torch.float32
2025-05-30 01:05:33,752 - data - INFO - 标签形状: torch.Size([47999, 12]), 类型: torch.float32
2025-05-30 01:05:33,752 - data - INFO - 标签类别数: 12
2025-05-30 01:05:33,752 - __main__ - INFO - 验证数据集大小: 47999
2025-05-30 01:05:33,758 - __main__ - INFO - 样本形状: torch.Size([30, 1]), 标签形状: torch.Size([12])
2025-05-30 01:05:33,758 - __main__ - INFO - 检测到 12 个类别
2025-05-30 01:05:33,758 - __main__ - INFO - 初始化LSTM模型...
2025-05-30 01:05:33,813 - model - INFO - 初始化GRUDetector: input_size=1, hidden_size=128, num_layers=2, num_classes=12, dropout_rate=0.5, bidirectional=True, model_type=gru
2025-05-30 01:05:35,358 - trainer - INFO - LSTM训练器初始化完成，设备: cuda, 学习率: 0.001, 权重衰减: 0.001, 梯度裁剪值: 1.0
2025-05-30 01:05:35,358 - __main__ - INFO - 开始训练LSTM模型...
2025-05-30 01:05:35,358 - trainer - INFO - 开始训练 8 个epochs...
2025-05-30 01:05:35,358 - trainer - INFO - 
Epoch 1/8
2025-05-30 10:31:40,203 - __main__ - INFO - 使用设备: cuda
2025-05-30 10:31:40,206 - __main__ - INFO - 加载数据集...
2025-05-30 10:31:40,206 - data - INFO - 开始数据处理流水线，模式: 训练
2025-05-30 10:31:40,206 - data - INFO - 开始读取文件: train_dataset.csv
2025-05-30 10:31:40,216 - data - INFO - CSV文件包含 45 个列
2025-05-30 10:31:40,216 - data - INFO - 将读取 45 列: 44 个特征列和 1 个标签列
2025-05-30 10:31:40,711 - data - INFO - 文件 train_dataset.csv 读取完成，shape=(192000, 45)
2025-05-30 10:31:40,715 - data - INFO - 开始数据清洗
2025-05-30 10:31:40,715 - data - INFO - 原始数据形状: (192000, 45)
2025-05-30 10:31:40,941 - data - INFO - 移除重复记录后剩余 191996 条记录
2025-05-30 10:31:40,954 - data - INFO - 处理前缺失值总数: 0
2025-05-30 10:31:41,189 - data - INFO - 处理了 364441 个异常值
2025-05-30 10:31:41,189 - data - INFO - 数据清洗完成，最终形状: (191996, 45)
2025-05-30 10:31:41,189 - data - INFO - 开始特征预处理
2025-05-30 10:31:41,241 - data - INFO - 对特征 ' Protocol' 进行独热编码，生成 3 个新特征
2025-05-30 10:31:41,279 - data - INFO - 标签类别: ['BENIGN', 'DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDP-lag']
2025-05-30 10:31:41,279 - data - INFO - 类别数量: 12
2025-05-30 10:31:41,363 - data - INFO - 找到 46 个数值特征
2025-05-30 10:31:41,525 - data - INFO - 保存了 46 个数值特征的顺序和scaler
2025-05-30 10:31:41,562 - data - INFO - 执行 PCA 降维: 从 46 维降至 30 维
2025-05-30 10:31:42,346 - data - INFO - PCA降维后保留信息量: 99.98%
2025-05-30 10:31:42,374 - data - INFO - PCA降维完成，最终特征维数: 30
2025-05-30 10:31:42,374 - data - INFO - 标签one-hot编码维数: 12
2025-05-30 10:31:42,437 - data - INFO - 最终特征形状: (191996, 30), 标签形状: (191996, 12)
2025-05-30 10:31:42,437 - data - INFO - 类别数量: 12
2025-05-30 10:31:42,437 - data - INFO - 数据处理流水线完成
2025-05-30 10:31:42,448 - data - INFO - 保存预处理器到: ./outputs\preprocessor.pkl
2025-05-30 10:31:42,449 - data - INFO - 预处理器已保存至 ./outputs\preprocessor.pkl
2025-05-30 10:31:42,449 - data - INFO - 预处理器保存成功
2025-05-30 10:31:42,449 - data - INFO - 特征数据类型: float64
2025-05-30 10:31:42,449 - data - INFO - 标签数据类型: float64
2025-05-30 10:31:42,463 - data - INFO - 特征形状: torch.Size([191996, 30]), 类型: torch.float32
2025-05-30 10:31:42,463 - data - INFO - 标签形状: torch.Size([191996, 12]), 类型: torch.float32
2025-05-30 10:31:42,463 - data - INFO - 标签类别数: 12
2025-05-30 10:31:42,463 - __main__ - INFO - 训练数据集大小: 191996
2025-05-30 10:31:42,463 - data - INFO - 加载预处理器从: ./outputs\preprocessor.pkl
2025-05-30 10:31:42,463 - data - INFO - 预处理器已从 ./outputs\preprocessor.pkl 加载，PCA维度: 30
2025-05-30 10:31:42,463 - data - INFO - 预处理器加载成功
2025-05-30 10:31:42,463 - data - INFO - 开始数据处理流水线，模式: 验证
2025-05-30 10:31:42,464 - data - INFO - 开始读取文件: test_dataset.csv
2025-05-30 10:31:42,469 - data - INFO - CSV文件包含 45 个列
2025-05-30 10:31:42,470 - data - INFO - 将读取 45 列: 44 个特征列和 1 个标签列
2025-05-30 10:31:42,600 - data - INFO - 文件 test_dataset.csv 读取完成，shape=(48000, 45)
2025-05-30 10:31:42,601 - data - INFO - 开始数据清洗
2025-05-30 10:31:42,602 - data - INFO - 原始数据形状: (48000, 45)
2025-05-30 10:31:42,647 - data - INFO - 移除重复记录后剩余 47999 条记录
2025-05-30 10:31:42,651 - data - INFO - 处理前缺失值总数: 0
2025-05-30 10:31:42,723 - data - INFO - 处理了 90815 个异常值
2025-05-30 10:31:42,723 - data - INFO - 数据清洗完成，最终形状: (47999, 45)
2025-05-30 10:31:42,723 - data - INFO - 开始特征预处理
2025-05-30 10:31:42,769 - data - INFO - 找到 46 个数值特征
2025-05-30 10:31:42,770 - data - INFO - 验证阶段使用 46 个特征
2025-05-30 10:31:42,843 - data - INFO - PCA降维完成，最终特征维数: 30
2025-05-30 10:31:42,843 - data - INFO - 标签one-hot编码维数: 12
2025-05-30 10:31:42,864 - data - INFO - 最终特征形状: (47999, 30), 标签形状: (47999, 12)
2025-05-30 10:31:42,864 - data - INFO - 类别数量: 12
2025-05-30 10:31:42,864 - data - INFO - 数据处理流水线完成
2025-05-30 10:31:42,869 - data - INFO - 特征数据类型: float64
2025-05-30 10:31:42,869 - data - INFO - 标签数据类型: float64
2025-05-30 10:31:42,873 - data - INFO - 特征形状: torch.Size([47999, 30]), 类型: torch.float32
2025-05-30 10:31:42,873 - data - INFO - 标签形状: torch.Size([47999, 12]), 类型: torch.float32
2025-05-30 10:31:42,873 - data - INFO - 标签类别数: 12
2025-05-30 10:31:42,873 - __main__ - INFO - 验证数据集大小: 47999
2025-05-30 10:31:42,877 - __main__ - INFO - 样本形状: torch.Size([30, 1]), 标签形状: torch.Size([12])
2025-05-30 10:31:42,877 - __main__ - INFO - 检测到 12 个类别
2025-05-30 10:31:42,878 - __main__ - INFO - 初始化LSTM模型...
2025-05-30 10:31:42,935 - model - INFO - 初始化GRUDetector: input_size=1, hidden_size=128, num_layers=2, num_classes=12, dropout_rate=0.5, bidirectional=True, model_type=gru
2025-05-30 10:31:44,918 - trainer - INFO - LSTM训练器初始化完成，设备: cuda, 学习率: 0.001, 权重衰减: 0.001, 梯度裁剪值: 1.0
2025-05-30 10:31:44,918 - __main__ - INFO - 开始训练LSTM模型...
2025-05-30 10:31:44,918 - trainer - INFO - 开始训练 8 个epochs...
2025-05-30 10:31:44,918 - trainer - INFO - 
Epoch 1/8
2025-05-30 10:31:59,319 - trainer - INFO - Epoch: 1 | Batch: 50/1500 | Loss: 2.1141 | Acc: 27.14% | Time: 14.40s
2025-05-30 10:31:59,555 - trainer - INFO - Epoch: 1 | Batch: 100/1500 | Loss: 1.8166 | Acc: 35.91% | Time: 14.64s
2025-05-30 10:31:59,759 - trainer - INFO - Epoch: 1 | Batch: 150/1500 | Loss: 1.6276 | Acc: 41.42% | Time: 14.84s
2025-05-30 10:31:59,973 - trainer - INFO - Epoch: 1 | Batch: 200/1500 | Loss: 1.5078 | Acc: 45.09% | Time: 15.05s
2025-05-30 10:32:00,243 - trainer - INFO - Epoch: 1 | Batch: 250/1500 | Loss: 1.4251 | Acc: 47.81% | Time: 15.33s
2025-05-30 10:32:00,484 - trainer - INFO - Epoch: 1 | Batch: 300/1500 | Loss: 1.3597 | Acc: 49.93% | Time: 15.57s
2025-05-30 10:32:00,687 - trainer - INFO - Epoch: 1 | Batch: 350/1500 | Loss: 1.3052 | Acc: 51.65% | Time: 15.77s
2025-05-30 10:32:00,876 - trainer - INFO - Epoch: 1 | Batch: 400/1500 | Loss: 1.2632 | Acc: 53.02% | Time: 15.96s
2025-05-30 10:32:01,073 - trainer - INFO - Epoch: 1 | Batch: 450/1500 | Loss: 1.2300 | Acc: 54.11% | Time: 16.16s
2025-05-30 10:32:01,266 - trainer - INFO - Epoch: 1 | Batch: 500/1500 | Loss: 1.2016 | Acc: 55.01% | Time: 16.35s
2025-05-30 10:32:01,463 - trainer - INFO - Epoch: 1 | Batch: 550/1500 | Loss: 1.1763 | Acc: 55.77% | Time: 16.54s
2025-05-30 10:32:01,664 - trainer - INFO - Epoch: 1 | Batch: 600/1500 | Loss: 1.1536 | Acc: 56.55% | Time: 16.75s
2025-05-30 10:32:01,849 - trainer - INFO - Epoch: 1 | Batch: 650/1500 | Loss: 1.1349 | Acc: 57.14% | Time: 16.93s
2025-05-30 10:32:02,036 - trainer - INFO - Epoch: 1 | Batch: 700/1500 | Loss: 1.1176 | Acc: 57.62% | Time: 17.12s
2025-05-30 10:32:02,221 - trainer - INFO - Epoch: 1 | Batch: 750/1500 | Loss: 1.1025 | Acc: 58.14% | Time: 17.30s
2025-05-30 10:32:02,413 - trainer - INFO - Epoch: 1 | Batch: 800/1500 | Loss: 1.0891 | Acc: 58.57% | Time: 17.49s
2025-05-30 10:32:02,601 - trainer - INFO - Epoch: 1 | Batch: 850/1500 | Loss: 1.0769 | Acc: 59.02% | Time: 17.68s
2025-05-30 10:32:02,790 - trainer - INFO - Epoch: 1 | Batch: 900/1500 | Loss: 1.0642 | Acc: 59.46% | Time: 17.87s
2025-05-30 10:32:02,992 - trainer - INFO - Epoch: 1 | Batch: 950/1500 | Loss: 1.0530 | Acc: 59.84% | Time: 18.07s
2025-05-30 10:32:03,193 - trainer - INFO - Epoch: 1 | Batch: 1000/1500 | Loss: 1.0427 | Acc: 60.25% | Time: 18.27s
2025-05-30 10:32:03,379 - trainer - INFO - Epoch: 1 | Batch: 1050/1500 | Loss: 1.0336 | Acc: 60.61% | Time: 18.46s
2025-05-30 10:32:03,571 - trainer - INFO - Epoch: 1 | Batch: 1100/1500 | Loss: 1.0242 | Acc: 60.94% | Time: 18.65s
2025-05-30 10:32:03,759 - trainer - INFO - Epoch: 1 | Batch: 1150/1500 | Loss: 1.0162 | Acc: 61.24% | Time: 18.84s
2025-05-30 10:32:03,948 - trainer - INFO - Epoch: 1 | Batch: 1200/1500 | Loss: 1.0084 | Acc: 61.52% | Time: 19.03s
2025-05-30 10:32:04,136 - trainer - INFO - Epoch: 1 | Batch: 1250/1500 | Loss: 0.9999 | Acc: 61.81% | Time: 19.22s
2025-05-30 10:32:04,324 - trainer - INFO - Epoch: 1 | Batch: 1300/1500 | Loss: 0.9938 | Acc: 62.01% | Time: 19.41s
2025-05-30 10:32:04,511 - trainer - INFO - Epoch: 1 | Batch: 1350/1500 | Loss: 0.9877 | Acc: 62.21% | Time: 19.59s
2025-05-30 10:32:04,697 - trainer - INFO - Epoch: 1 | Batch: 1400/1500 | Loss: 0.9810 | Acc: 62.46% | Time: 19.78s
2025-05-30 10:32:04,888 - trainer - INFO - Epoch: 1 | Batch: 1450/1500 | Loss: 0.9760 | Acc: 62.62% | Time: 19.97s
2025-05-30 10:32:05,084 - trainer - INFO - Epoch: 1 | Batch: 1500/1500 | Loss: 0.9697 | Acc: 62.81% | Time: 20.17s
2025-05-30 10:32:18,531 - trainer - INFO - 验证 | Loss: 0.7301 | Acc: 71.67%
2025-05-30 10:32:18,545 - trainer - INFO - 最佳模型已保存，epoch 1，验证损失: 0.7301
2025-05-30 10:32:18,545 - trainer - INFO - 
Epoch 2/8
2025-05-30 10:32:30,924 - trainer - INFO - Epoch: 2 | Batch: 50/1500 | Loss: 0.7882 | Acc: 68.88% | Time: 12.38s
2025-05-30 10:32:31,147 - trainer - INFO - Epoch: 2 | Batch: 100/1500 | Loss: 0.7895 | Acc: 69.25% | Time: 12.60s
2025-05-30 10:32:31,344 - trainer - INFO - Epoch: 2 | Batch: 150/1500 | Loss: 0.7880 | Acc: 69.33% | Time: 12.80s
2025-05-30 10:32:31,545 - trainer - INFO - Epoch: 2 | Batch: 200/1500 | Loss: 0.7932 | Acc: 69.12% | Time: 13.00s
2025-05-30 10:32:31,782 - trainer - INFO - Epoch: 2 | Batch: 250/1500 | Loss: 0.7912 | Acc: 69.16% | Time: 13.24s
2025-05-30 10:32:32,011 - trainer - INFO - Epoch: 2 | Batch: 300/1500 | Loss: 0.7897 | Acc: 69.23% | Time: 13.47s
2025-05-30 10:32:32,294 - trainer - INFO - Epoch: 2 | Batch: 350/1500 | Loss: 0.7876 | Acc: 69.34% | Time: 13.75s
2025-05-30 10:32:32,559 - trainer - INFO - Epoch: 2 | Batch: 400/1500 | Loss: 0.7878 | Acc: 69.31% | Time: 14.01s
2025-05-30 10:32:32,826 - trainer - INFO - Epoch: 2 | Batch: 450/1500 | Loss: 0.7881 | Acc: 69.35% | Time: 14.28s
2025-05-30 10:32:33,069 - trainer - INFO - Epoch: 2 | Batch: 500/1500 | Loss: 0.7856 | Acc: 69.39% | Time: 14.52s
2025-05-30 10:32:33,294 - trainer - INFO - Epoch: 2 | Batch: 550/1500 | Loss: 0.7854 | Acc: 69.44% | Time: 14.75s
2025-05-30 10:32:33,496 - trainer - INFO - Epoch: 2 | Batch: 600/1500 | Loss: 0.7822 | Acc: 69.60% | Time: 14.95s
2025-05-30 10:32:33,716 - trainer - INFO - Epoch: 2 | Batch: 650/1500 | Loss: 0.7811 | Acc: 69.63% | Time: 15.17s
2025-05-30 10:32:33,959 - trainer - INFO - Epoch: 2 | Batch: 700/1500 | Loss: 0.7801 | Acc: 69.67% | Time: 15.41s
2025-05-30 10:32:34,189 - trainer - INFO - Epoch: 2 | Batch: 750/1500 | Loss: 0.7802 | Acc: 69.66% | Time: 15.64s
2025-05-30 10:32:34,397 - trainer - INFO - Epoch: 2 | Batch: 800/1500 | Loss: 0.7796 | Acc: 69.69% | Time: 15.85s
2025-05-30 10:32:34,620 - trainer - INFO - Epoch: 2 | Batch: 850/1500 | Loss: 0.7803 | Acc: 69.69% | Time: 16.08s
2025-05-30 10:32:34,817 - trainer - INFO - Epoch: 2 | Batch: 900/1500 | Loss: 0.7791 | Acc: 69.70% | Time: 16.27s
2025-05-30 10:32:35,049 - trainer - INFO - Epoch: 2 | Batch: 950/1500 | Loss: 0.7795 | Acc: 69.67% | Time: 16.50s
2025-05-30 10:32:35,259 - trainer - INFO - Epoch: 2 | Batch: 1000/1500 | Loss: 0.7791 | Acc: 69.69% | Time: 16.71s
2025-05-30 10:32:35,475 - trainer - INFO - Epoch: 2 | Batch: 1050/1500 | Loss: 0.7784 | Acc: 69.72% | Time: 16.93s
2025-05-30 10:32:35,679 - trainer - INFO - Epoch: 2 | Batch: 1100/1500 | Loss: 0.7769 | Acc: 69.76% | Time: 17.13s
2025-05-30 10:32:35,894 - trainer - INFO - Epoch: 2 | Batch: 1150/1500 | Loss: 0.7761 | Acc: 69.80% | Time: 17.35s
2025-05-30 10:32:36,154 - trainer - INFO - Epoch: 2 | Batch: 1200/1500 | Loss: 0.7755 | Acc: 69.82% | Time: 17.61s
2025-05-30 10:32:36,385 - trainer - INFO - Epoch: 2 | Batch: 1250/1500 | Loss: 0.7756 | Acc: 69.83% | Time: 17.84s
2025-05-30 10:32:36,586 - trainer - INFO - Epoch: 2 | Batch: 1300/1500 | Loss: 0.7751 | Acc: 69.85% | Time: 18.04s
2025-05-30 10:32:36,777 - trainer - INFO - Epoch: 2 | Batch: 1350/1500 | Loss: 0.7750 | Acc: 69.86% | Time: 18.23s
2025-05-30 10:32:36,977 - trainer - INFO - Epoch: 2 | Batch: 1400/1500 | Loss: 0.7750 | Acc: 69.85% | Time: 18.43s
2025-05-30 10:32:37,180 - trainer - INFO - Epoch: 2 | Batch: 1450/1500 | Loss: 0.7750 | Acc: 69.82% | Time: 18.63s
2025-05-30 10:32:37,391 - trainer - INFO - Epoch: 2 | Batch: 1500/1500 | Loss: 0.7751 | Acc: 69.83% | Time: 18.85s
2025-05-30 10:32:51,526 - trainer - INFO - 验证 | Loss: 0.7069 | Acc: 71.67%
2025-05-30 10:32:51,539 - trainer - INFO - 最佳模型已保存，epoch 2，验证损失: 0.7069
2025-05-30 10:32:51,539 - trainer - INFO - 
Epoch 3/8
2025-05-30 10:33:04,497 - trainer - INFO - Epoch: 3 | Batch: 50/1500 | Loss: 0.7539 | Acc: 71.34% | Time: 12.96s
2025-05-30 10:33:04,700 - trainer - INFO - Epoch: 3 | Batch: 100/1500 | Loss: 0.7505 | Acc: 71.05% | Time: 13.16s
2025-05-30 10:33:04,896 - trainer - INFO - Epoch: 3 | Batch: 150/1500 | Loss: 0.7549 | Acc: 70.75% | Time: 13.36s
2025-05-30 10:33:05,097 - trainer - INFO - Epoch: 3 | Batch: 200/1500 | Loss: 0.7533 | Acc: 70.59% | Time: 13.56s
2025-05-30 10:33:05,291 - trainer - INFO - Epoch: 3 | Batch: 250/1500 | Loss: 0.7532 | Acc: 70.38% | Time: 13.75s
2025-05-30 10:33:05,486 - trainer - INFO - Epoch: 3 | Batch: 300/1500 | Loss: 0.7529 | Acc: 70.39% | Time: 13.95s
2025-05-30 10:33:05,688 - trainer - INFO - Epoch: 3 | Batch: 350/1500 | Loss: 0.7524 | Acc: 70.52% | Time: 14.15s
2025-05-30 10:33:05,883 - trainer - INFO - Epoch: 3 | Batch: 400/1500 | Loss: 0.7523 | Acc: 70.48% | Time: 14.34s
2025-05-30 10:33:06,083 - trainer - INFO - Epoch: 3 | Batch: 450/1500 | Loss: 0.7528 | Acc: 70.47% | Time: 14.54s
2025-05-30 10:33:06,279 - trainer - INFO - Epoch: 3 | Batch: 500/1500 | Loss: 0.7536 | Acc: 70.44% | Time: 14.74s
2025-05-30 10:33:06,476 - trainer - INFO - Epoch: 3 | Batch: 550/1500 | Loss: 0.7531 | Acc: 70.54% | Time: 14.94s
2025-05-30 10:33:06,676 - trainer - INFO - Epoch: 3 | Batch: 600/1500 | Loss: 0.7531 | Acc: 70.57% | Time: 15.14s
2025-05-30 10:33:06,873 - trainer - INFO - Epoch: 3 | Batch: 650/1500 | Loss: 0.7514 | Acc: 70.58% | Time: 15.33s
2025-05-30 10:33:07,073 - trainer - INFO - Epoch: 3 | Batch: 700/1500 | Loss: 0.7535 | Acc: 70.48% | Time: 15.53s
2025-05-30 10:33:07,297 - trainer - INFO - Epoch: 3 | Batch: 750/1500 | Loss: 0.7532 | Acc: 70.50% | Time: 15.76s
2025-05-30 10:33:07,491 - trainer - INFO - Epoch: 3 | Batch: 800/1500 | Loss: 0.7538 | Acc: 70.47% | Time: 15.95s
2025-05-30 10:33:07,687 - trainer - INFO - Epoch: 3 | Batch: 850/1500 | Loss: 0.7540 | Acc: 70.49% | Time: 16.15s
2025-05-30 10:33:07,881 - trainer - INFO - Epoch: 3 | Batch: 900/1500 | Loss: 0.7531 | Acc: 70.51% | Time: 16.34s
2025-05-30 10:33:08,089 - trainer - INFO - Epoch: 3 | Batch: 950/1500 | Loss: 0.7522 | Acc: 70.53% | Time: 16.55s
2025-05-30 10:33:08,283 - trainer - INFO - Epoch: 3 | Batch: 1000/1500 | Loss: 0.7518 | Acc: 70.57% | Time: 16.74s
2025-05-30 10:33:08,477 - trainer - INFO - Epoch: 3 | Batch: 1050/1500 | Loss: 0.7515 | Acc: 70.59% | Time: 16.94s
2025-05-30 10:33:08,670 - trainer - INFO - Epoch: 3 | Batch: 1100/1500 | Loss: 0.7515 | Acc: 70.62% | Time: 17.13s
2025-05-30 10:33:08,866 - trainer - INFO - Epoch: 3 | Batch: 1150/1500 | Loss: 0.7513 | Acc: 70.61% | Time: 17.33s
2025-05-30 10:33:09,066 - trainer - INFO - Epoch: 3 | Batch: 1200/1500 | Loss: 0.7514 | Acc: 70.60% | Time: 17.53s
2025-05-30 10:33:09,284 - trainer - INFO - Epoch: 3 | Batch: 1250/1500 | Loss: 0.7513 | Acc: 70.61% | Time: 17.74s
2025-05-30 10:33:09,516 - trainer - INFO - Epoch: 3 | Batch: 1300/1500 | Loss: 0.7506 | Acc: 70.63% | Time: 17.98s
2025-05-30 10:33:09,728 - trainer - INFO - Epoch: 3 | Batch: 1350/1500 | Loss: 0.7501 | Acc: 70.62% | Time: 18.19s
2025-05-30 10:33:09,929 - trainer - INFO - Epoch: 3 | Batch: 1400/1500 | Loss: 0.7489 | Acc: 70.67% | Time: 18.39s
2025-05-30 10:33:10,122 - trainer - INFO - Epoch: 3 | Batch: 1450/1500 | Loss: 0.7478 | Acc: 70.70% | Time: 18.58s
2025-05-30 10:33:10,361 - trainer - INFO - Epoch: 3 | Batch: 1500/1500 | Loss: 0.7471 | Acc: 70.72% | Time: 18.82s
2025-05-30 10:33:24,653 - trainer - INFO - 验证 | Loss: 0.6789 | Acc: 72.70%
2025-05-30 10:33:24,663 - trainer - INFO - 最佳模型已保存，epoch 3，验证损失: 0.6789
2025-05-30 10:33:24,663 - trainer - INFO - 
Epoch 4/8
2025-05-30 10:33:37,075 - trainer - INFO - Epoch: 4 | Batch: 50/1500 | Loss: 0.7409 | Acc: 71.02% | Time: 12.41s
2025-05-30 10:33:37,317 - trainer - INFO - Epoch: 4 | Batch: 100/1500 | Loss: 0.7320 | Acc: 71.29% | Time: 12.65s
2025-05-30 10:33:37,593 - trainer - INFO - Epoch: 4 | Batch: 150/1500 | Loss: 0.7246 | Acc: 71.62% | Time: 12.93s
2025-05-30 10:33:37,800 - trainer - INFO - Epoch: 4 | Batch: 200/1500 | Loss: 0.7338 | Acc: 71.13% | Time: 13.14s
2025-05-30 10:33:37,996 - trainer - INFO - Epoch: 4 | Batch: 250/1500 | Loss: 0.7315 | Acc: 71.17% | Time: 13.33s
2025-05-30 10:33:38,200 - trainer - INFO - Epoch: 4 | Batch: 300/1500 | Loss: 0.7337 | Acc: 71.04% | Time: 13.54s
2025-05-30 10:33:38,468 - trainer - INFO - Epoch: 4 | Batch: 350/1500 | Loss: 0.7351 | Acc: 71.02% | Time: 13.80s
2025-05-30 10:33:38,722 - trainer - INFO - Epoch: 4 | Batch: 400/1500 | Loss: 0.7341 | Acc: 71.07% | Time: 14.06s
2025-05-30 10:33:39,006 - trainer - INFO - Epoch: 4 | Batch: 450/1500 | Loss: 0.7336 | Acc: 71.19% | Time: 14.34s
2025-05-30 10:33:39,312 - trainer - INFO - Epoch: 4 | Batch: 500/1500 | Loss: 0.7337 | Acc: 71.22% | Time: 14.65s
2025-05-30 10:33:39,843 - trainer - INFO - Epoch: 4 | Batch: 550/1500 | Loss: 0.7346 | Acc: 71.18% | Time: 15.18s
2025-05-30 10:33:40,075 - trainer - INFO - Epoch: 4 | Batch: 600/1500 | Loss: 0.7345 | Acc: 71.18% | Time: 15.41s
2025-05-30 10:33:40,297 - trainer - INFO - Epoch: 4 | Batch: 650/1500 | Loss: 0.7336 | Acc: 71.24% | Time: 15.63s
2025-05-30 10:33:40,515 - trainer - INFO - Epoch: 4 | Batch: 700/1500 | Loss: 0.7327 | Acc: 71.25% | Time: 15.85s
2025-05-30 10:33:40,732 - trainer - INFO - Epoch: 4 | Batch: 750/1500 | Loss: 0.7332 | Acc: 71.22% | Time: 16.07s
2025-05-30 10:33:40,926 - trainer - INFO - Epoch: 4 | Batch: 800/1500 | Loss: 0.7333 | Acc: 71.25% | Time: 16.26s
2025-05-30 10:33:41,118 - trainer - INFO - Epoch: 4 | Batch: 850/1500 | Loss: 0.7338 | Acc: 71.25% | Time: 16.45s
2025-05-30 10:33:41,317 - trainer - INFO - Epoch: 4 | Batch: 900/1500 | Loss: 0.7348 | Acc: 71.19% | Time: 16.65s
2025-05-30 10:33:41,514 - trainer - INFO - Epoch: 4 | Batch: 950/1500 | Loss: 0.7351 | Acc: 71.19% | Time: 16.85s
2025-05-30 10:33:41,725 - trainer - INFO - Epoch: 4 | Batch: 1000/1500 | Loss: 0.7350 | Acc: 71.20% | Time: 17.06s
2025-05-30 10:33:42,009 - trainer - INFO - Epoch: 4 | Batch: 1050/1500 | Loss: 0.7346 | Acc: 71.21% | Time: 17.35s
2025-05-30 10:33:42,238 - trainer - INFO - Epoch: 4 | Batch: 1100/1500 | Loss: 0.7343 | Acc: 71.24% | Time: 17.57s
2025-05-30 10:33:42,440 - trainer - INFO - Epoch: 4 | Batch: 1150/1500 | Loss: 0.7340 | Acc: 71.27% | Time: 17.78s
2025-05-30 10:33:42,633 - trainer - INFO - Epoch: 4 | Batch: 1200/1500 | Loss: 0.7347 | Acc: 71.26% | Time: 17.97s
2025-05-30 10:33:42,835 - trainer - INFO - Epoch: 4 | Batch: 1250/1500 | Loss: 0.7345 | Acc: 71.27% | Time: 18.17s
2025-05-30 10:33:43,042 - trainer - INFO - Epoch: 4 | Batch: 1300/1500 | Loss: 0.7346 | Acc: 71.26% | Time: 18.38s
2025-05-30 10:33:43,244 - trainer - INFO - Epoch: 4 | Batch: 1350/1500 | Loss: 0.7334 | Acc: 71.30% | Time: 18.58s
2025-05-30 10:33:43,444 - trainer - INFO - Epoch: 4 | Batch: 1400/1500 | Loss: 0.7330 | Acc: 71.29% | Time: 18.78s
2025-05-30 10:33:43,657 - trainer - INFO - Epoch: 4 | Batch: 1450/1500 | Loss: 0.7321 | Acc: 71.31% | Time: 18.99s
2025-05-30 10:33:43,891 - trainer - INFO - Epoch: 4 | Batch: 1500/1500 | Loss: 0.7324 | Acc: 71.30% | Time: 19.23s
2025-05-30 10:33:57,362 - trainer - INFO - 验证 | Loss: 0.6677 | Acc: 72.25%
2025-05-30 10:33:57,373 - trainer - INFO - 最佳模型已保存，epoch 4，验证损失: 0.6677
2025-05-30 10:33:57,373 - trainer - INFO - 
Epoch 5/8
2025-05-30 10:34:10,668 - trainer - INFO - Epoch: 5 | Batch: 50/1500 | Loss: 0.7248 | Acc: 71.80% | Time: 13.29s
2025-05-30 10:34:10,874 - trainer - INFO - Epoch: 5 | Batch: 100/1500 | Loss: 0.7347 | Acc: 71.44% | Time: 13.50s
2025-05-30 10:34:11,107 - trainer - INFO - Epoch: 5 | Batch: 150/1500 | Loss: 0.7308 | Acc: 71.33% | Time: 13.73s
2025-05-30 10:34:11,310 - trainer - INFO - Epoch: 5 | Batch: 200/1500 | Loss: 0.7298 | Acc: 71.34% | Time: 13.94s
2025-05-30 10:34:11,513 - trainer - INFO - Epoch: 5 | Batch: 250/1500 | Loss: 0.7295 | Acc: 71.38% | Time: 14.14s
2025-05-30 10:34:11,722 - trainer - INFO - Epoch: 5 | Batch: 300/1500 | Loss: 0.7256 | Acc: 71.42% | Time: 14.35s
2025-05-30 10:34:11,921 - trainer - INFO - Epoch: 5 | Batch: 350/1500 | Loss: 0.7259 | Acc: 71.50% | Time: 14.55s
2025-05-30 10:34:12,129 - trainer - INFO - Epoch: 5 | Batch: 400/1500 | Loss: 0.7241 | Acc: 71.56% | Time: 14.75s
2025-05-30 10:34:12,355 - trainer - INFO - Epoch: 5 | Batch: 450/1500 | Loss: 0.7225 | Acc: 71.62% | Time: 14.98s
2025-05-30 10:34:12,565 - trainer - INFO - Epoch: 5 | Batch: 500/1500 | Loss: 0.7224 | Acc: 71.56% | Time: 15.19s
2025-05-30 10:34:12,764 - trainer - INFO - Epoch: 5 | Batch: 550/1500 | Loss: 0.7229 | Acc: 71.55% | Time: 15.39s
2025-05-30 10:34:12,959 - trainer - INFO - Epoch: 5 | Batch: 600/1500 | Loss: 0.7236 | Acc: 71.54% | Time: 15.59s
2025-05-30 10:34:13,152 - trainer - INFO - Epoch: 5 | Batch: 650/1500 | Loss: 0.7240 | Acc: 71.45% | Time: 15.78s
2025-05-30 10:34:13,350 - trainer - INFO - Epoch: 5 | Batch: 700/1500 | Loss: 0.7241 | Acc: 71.44% | Time: 15.98s
2025-05-30 10:34:13,548 - trainer - INFO - Epoch: 5 | Batch: 750/1500 | Loss: 0.7242 | Acc: 71.38% | Time: 16.18s
2025-05-30 10:34:13,746 - trainer - INFO - Epoch: 5 | Batch: 800/1500 | Loss: 0.7242 | Acc: 71.37% | Time: 16.37s
2025-05-30 10:34:13,971 - trainer - INFO - Epoch: 5 | Batch: 850/1500 | Loss: 0.7248 | Acc: 71.36% | Time: 16.60s
2025-05-30 10:34:14,176 - trainer - INFO - Epoch: 5 | Batch: 900/1500 | Loss: 0.7244 | Acc: 71.38% | Time: 16.80s
2025-05-30 10:34:14,372 - trainer - INFO - Epoch: 5 | Batch: 950/1500 | Loss: 0.7235 | Acc: 71.45% | Time: 17.00s
2025-05-30 10:34:14,579 - trainer - INFO - Epoch: 5 | Batch: 1000/1500 | Loss: 0.7233 | Acc: 71.46% | Time: 17.21s
2025-05-30 10:34:14,773 - trainer - INFO - Epoch: 5 | Batch: 1050/1500 | Loss: 0.7232 | Acc: 71.47% | Time: 17.40s
2025-05-30 10:34:14,983 - trainer - INFO - Epoch: 5 | Batch: 1100/1500 | Loss: 0.7231 | Acc: 71.47% | Time: 17.61s
2025-05-30 10:34:15,175 - trainer - INFO - Epoch: 5 | Batch: 1150/1500 | Loss: 0.7232 | Acc: 71.50% | Time: 17.80s
2025-05-30 10:34:15,403 - trainer - INFO - Epoch: 5 | Batch: 1200/1500 | Loss: 0.7227 | Acc: 71.53% | Time: 18.03s
2025-05-30 10:34:15,602 - trainer - INFO - Epoch: 5 | Batch: 1250/1500 | Loss: 0.7215 | Acc: 71.55% | Time: 18.23s
2025-05-30 10:34:15,792 - trainer - INFO - Epoch: 5 | Batch: 1300/1500 | Loss: 0.7225 | Acc: 71.53% | Time: 18.42s
2025-05-30 10:34:16,006 - trainer - INFO - Epoch: 5 | Batch: 1350/1500 | Loss: 0.7223 | Acc: 71.52% | Time: 18.63s
2025-05-30 10:34:16,257 - trainer - INFO - Epoch: 5 | Batch: 1400/1500 | Loss: 0.7224 | Acc: 71.51% | Time: 18.88s
2025-05-30 10:34:16,498 - trainer - INFO - Epoch: 5 | Batch: 1450/1500 | Loss: 0.7228 | Acc: 71.50% | Time: 19.12s
2025-05-30 10:34:16,733 - trainer - INFO - Epoch: 5 | Batch: 1500/1500 | Loss: 0.7223 | Acc: 71.53% | Time: 19.36s
2025-05-30 10:34:32,571 - trainer - INFO - 验证 | Loss: 0.6880 | Acc: 71.73%
2025-05-30 10:34:32,571 - trainer - INFO - 验证损失未改善。耐心计数: 1/10
2025-05-30 10:34:32,582 - trainer - INFO - 
Epoch 6/8
2025-05-30 10:34:45,249 - trainer - INFO - Epoch: 6 | Batch: 50/1500 | Loss: 0.7300 | Acc: 71.06% | Time: 12.67s
2025-05-30 10:34:45,463 - trainer - INFO - Epoch: 6 | Batch: 100/1500 | Loss: 0.7238 | Acc: 71.51% | Time: 12.88s
2025-05-30 10:34:45,663 - trainer - INFO - Epoch: 6 | Batch: 150/1500 | Loss: 0.7177 | Acc: 71.57% | Time: 13.08s
2025-05-30 10:34:45,866 - trainer - INFO - Epoch: 6 | Batch: 200/1500 | Loss: 0.7190 | Acc: 71.56% | Time: 13.28s
2025-05-30 10:34:46,065 - trainer - INFO - Epoch: 6 | Batch: 250/1500 | Loss: 0.7196 | Acc: 71.63% | Time: 13.48s
2025-05-30 10:34:46,264 - trainer - INFO - Epoch: 6 | Batch: 300/1500 | Loss: 0.7205 | Acc: 71.55% | Time: 13.68s
2025-05-30 10:34:46,463 - trainer - INFO - Epoch: 6 | Batch: 350/1500 | Loss: 0.7200 | Acc: 71.65% | Time: 13.88s
2025-05-30 10:34:46,666 - trainer - INFO - Epoch: 6 | Batch: 400/1500 | Loss: 0.7225 | Acc: 71.61% | Time: 14.08s
2025-05-30 10:34:46,864 - trainer - INFO - Epoch: 6 | Batch: 450/1500 | Loss: 0.7208 | Acc: 71.77% | Time: 14.28s
2025-05-30 10:34:47,070 - trainer - INFO - Epoch: 6 | Batch: 500/1500 | Loss: 0.7224 | Acc: 71.74% | Time: 14.49s
2025-05-30 10:34:47,264 - trainer - INFO - Epoch: 6 | Batch: 550/1500 | Loss: 0.7218 | Acc: 71.76% | Time: 14.68s
2025-05-30 10:34:47,464 - trainer - INFO - Epoch: 6 | Batch: 600/1500 | Loss: 0.7225 | Acc: 71.73% | Time: 14.88s
2025-05-30 10:34:47,660 - trainer - INFO - Epoch: 6 | Batch: 650/1500 | Loss: 0.7214 | Acc: 71.77% | Time: 15.08s
2025-05-30 10:34:47,866 - trainer - INFO - Epoch: 6 | Batch: 700/1500 | Loss: 0.7207 | Acc: 71.75% | Time: 15.28s
2025-05-30 10:34:48,068 - trainer - INFO - Epoch: 6 | Batch: 750/1500 | Loss: 0.7200 | Acc: 71.77% | Time: 15.49s
2025-05-30 10:34:48,275 - trainer - INFO - Epoch: 6 | Batch: 800/1500 | Loss: 0.7197 | Acc: 71.81% | Time: 15.69s
2025-05-30 10:34:48,487 - trainer - INFO - Epoch: 6 | Batch: 850/1500 | Loss: 0.7199 | Acc: 71.79% | Time: 15.90s
2025-05-30 10:34:48,694 - trainer - INFO - Epoch: 6 | Batch: 900/1500 | Loss: 0.7191 | Acc: 71.81% | Time: 16.11s
2025-05-30 10:34:48,890 - trainer - INFO - Epoch: 6 | Batch: 950/1500 | Loss: 0.7176 | Acc: 71.87% | Time: 16.31s
2025-05-30 10:34:49,109 - trainer - INFO - Epoch: 6 | Batch: 1000/1500 | Loss: 0.7177 | Acc: 71.87% | Time: 16.53s
2025-05-30 10:34:49,302 - trainer - INFO - Epoch: 6 | Batch: 1050/1500 | Loss: 0.7184 | Acc: 71.82% | Time: 16.72s
2025-05-30 10:34:49,498 - trainer - INFO - Epoch: 6 | Batch: 1100/1500 | Loss: 0.7188 | Acc: 71.80% | Time: 16.92s
2025-05-30 10:34:49,696 - trainer - INFO - Epoch: 6 | Batch: 1150/1500 | Loss: 0.7181 | Acc: 71.82% | Time: 17.11s
2025-05-30 10:34:49,885 - trainer - INFO - Epoch: 6 | Batch: 1200/1500 | Loss: 0.7178 | Acc: 71.83% | Time: 17.30s
2025-05-30 10:34:50,079 - trainer - INFO - Epoch: 6 | Batch: 1250/1500 | Loss: 0.7191 | Acc: 71.75% | Time: 17.50s
2025-05-30 10:34:50,277 - trainer - INFO - Epoch: 6 | Batch: 1300/1500 | Loss: 0.7193 | Acc: 71.73% | Time: 17.70s
2025-05-30 10:34:50,472 - trainer - INFO - Epoch: 6 | Batch: 1350/1500 | Loss: 0.7194 | Acc: 71.71% | Time: 17.89s
2025-05-30 10:34:50,679 - trainer - INFO - Epoch: 6 | Batch: 1400/1500 | Loss: 0.7196 | Acc: 71.70% | Time: 18.10s
2025-05-30 10:34:50,876 - trainer - INFO - Epoch: 6 | Batch: 1450/1500 | Loss: 0.7193 | Acc: 71.70% | Time: 18.29s
2025-05-30 10:34:51,089 - trainer - INFO - Epoch: 6 | Batch: 1500/1500 | Loss: 0.7195 | Acc: 71.70% | Time: 18.51s
2025-05-30 10:35:05,329 - trainer - INFO - 验证 | Loss: 0.6698 | Acc: 74.13%
2025-05-30 10:35:05,330 - trainer - INFO - 验证损失未改善。耐心计数: 2/10
2025-05-30 10:35:05,330 - trainer - INFO - 
Epoch 7/8
2025-05-30 10:35:18,475 - trainer - INFO - Epoch: 7 | Batch: 50/1500 | Loss: 0.7252 | Acc: 71.58% | Time: 13.14s
2025-05-30 10:35:18,694 - trainer - INFO - Epoch: 7 | Batch: 100/1500 | Loss: 0.7085 | Acc: 72.02% | Time: 13.36s
2025-05-30 10:35:18,906 - trainer - INFO - Epoch: 7 | Batch: 150/1500 | Loss: 0.7037 | Acc: 72.18% | Time: 13.58s
2025-05-30 10:35:19,137 - trainer - INFO - Epoch: 7 | Batch: 200/1500 | Loss: 0.7033 | Acc: 72.26% | Time: 13.81s
2025-05-30 10:35:19,351 - trainer - INFO - Epoch: 7 | Batch: 250/1500 | Loss: 0.7060 | Acc: 72.20% | Time: 14.02s
2025-05-30 10:35:19,559 - trainer - INFO - Epoch: 7 | Batch: 300/1500 | Loss: 0.7053 | Acc: 72.24% | Time: 14.23s
2025-05-30 10:35:19,768 - trainer - INFO - Epoch: 7 | Batch: 350/1500 | Loss: 0.7067 | Acc: 72.17% | Time: 14.44s
2025-05-30 10:35:19,997 - trainer - INFO - Epoch: 7 | Batch: 400/1500 | Loss: 0.7086 | Acc: 72.15% | Time: 14.67s
2025-05-30 10:35:20,197 - trainer - INFO - Epoch: 7 | Batch: 450/1500 | Loss: 0.7082 | Acc: 72.12% | Time: 14.87s
2025-05-30 10:35:20,382 - trainer - INFO - Epoch: 7 | Batch: 500/1500 | Loss: 0.7068 | Acc: 72.21% | Time: 15.05s
2025-05-30 10:35:20,588 - trainer - INFO - Epoch: 7 | Batch: 550/1500 | Loss: 0.7070 | Acc: 72.19% | Time: 15.26s
2025-05-30 10:35:20,783 - trainer - INFO - Epoch: 7 | Batch: 600/1500 | Loss: 0.7101 | Acc: 72.09% | Time: 15.45s
2025-05-30 10:35:20,994 - trainer - INFO - Epoch: 7 | Batch: 650/1500 | Loss: 0.7114 | Acc: 72.06% | Time: 15.66s
2025-05-30 10:35:21,204 - trainer - INFO - Epoch: 7 | Batch: 700/1500 | Loss: 0.7131 | Acc: 72.00% | Time: 15.87s
2025-05-30 10:35:21,423 - trainer - INFO - Epoch: 7 | Batch: 750/1500 | Loss: 0.7128 | Acc: 72.07% | Time: 16.09s
2025-05-30 10:35:21,640 - trainer - INFO - Epoch: 7 | Batch: 800/1500 | Loss: 0.7130 | Acc: 72.08% | Time: 16.31s
2025-05-30 10:35:21,843 - trainer - INFO - Epoch: 7 | Batch: 850/1500 | Loss: 0.7135 | Acc: 72.06% | Time: 16.51s
2025-05-30 10:35:22,050 - trainer - INFO - Epoch: 7 | Batch: 900/1500 | Loss: 0.7140 | Acc: 72.00% | Time: 16.72s
2025-05-30 10:35:22,254 - trainer - INFO - Epoch: 7 | Batch: 950/1500 | Loss: 0.7135 | Acc: 72.02% | Time: 16.92s
2025-05-30 10:35:22,453 - trainer - INFO - Epoch: 7 | Batch: 1000/1500 | Loss: 0.7128 | Acc: 72.05% | Time: 17.12s
2025-05-30 10:35:22,649 - trainer - INFO - Epoch: 7 | Batch: 1050/1500 | Loss: 0.7124 | Acc: 72.06% | Time: 17.32s
2025-05-30 10:35:22,839 - trainer - INFO - Epoch: 7 | Batch: 1100/1500 | Loss: 0.7133 | Acc: 72.00% | Time: 17.51s
2025-05-30 10:35:23,043 - trainer - INFO - Epoch: 7 | Batch: 1150/1500 | Loss: 0.7134 | Acc: 71.98% | Time: 17.71s
2025-05-30 10:35:23,262 - trainer - INFO - Epoch: 7 | Batch: 1200/1500 | Loss: 0.7136 | Acc: 71.97% | Time: 17.93s
2025-05-30 10:35:23,450 - trainer - INFO - Epoch: 7 | Batch: 1250/1500 | Loss: 0.7131 | Acc: 72.00% | Time: 18.12s
2025-05-30 10:35:23,638 - trainer - INFO - Epoch: 7 | Batch: 1300/1500 | Loss: 0.7142 | Acc: 71.96% | Time: 18.31s
2025-05-30 10:35:23,823 - trainer - INFO - Epoch: 7 | Batch: 1350/1500 | Loss: 0.7139 | Acc: 71.95% | Time: 18.49s
2025-05-30 10:35:24,011 - trainer - INFO - Epoch: 7 | Batch: 1400/1500 | Loss: 0.7138 | Acc: 71.95% | Time: 18.68s
2025-05-30 10:35:24,202 - trainer - INFO - Epoch: 7 | Batch: 1450/1500 | Loss: 0.7138 | Acc: 71.97% | Time: 18.87s
2025-05-30 10:35:24,394 - trainer - INFO - Epoch: 7 | Batch: 1500/1500 | Loss: 0.7143 | Acc: 71.95% | Time: 19.06s
2025-05-30 10:35:39,019 - trainer - INFO - 验证 | Loss: 0.6643 | Acc: 73.07%
2025-05-30 10:35:39,028 - trainer - INFO - 最佳模型已保存，epoch 7，验证损失: 0.6643
2025-05-30 10:35:39,028 - trainer - INFO - 
Epoch 8/8
2025-05-30 10:35:51,428 - trainer - INFO - Epoch: 8 | Batch: 50/1500 | Loss: 0.7140 | Acc: 72.52% | Time: 12.40s
2025-05-30 10:35:51,613 - trainer - INFO - Epoch: 8 | Batch: 100/1500 | Loss: 0.6995 | Acc: 72.54% | Time: 12.58s
2025-05-30 10:35:51,795 - trainer - INFO - Epoch: 8 | Batch: 150/1500 | Loss: 0.7091 | Acc: 72.36% | Time: 12.77s
2025-05-30 10:35:51,985 - trainer - INFO - Epoch: 8 | Batch: 200/1500 | Loss: 0.7120 | Acc: 72.14% | Time: 12.96s
2025-05-30 10:35:52,174 - trainer - INFO - Epoch: 8 | Batch: 250/1500 | Loss: 0.7126 | Acc: 72.01% | Time: 13.15s
2025-05-30 10:35:52,368 - trainer - INFO - Epoch: 8 | Batch: 300/1500 | Loss: 0.7129 | Acc: 72.01% | Time: 13.34s
2025-05-30 10:35:52,552 - trainer - INFO - Epoch: 8 | Batch: 350/1500 | Loss: 0.7119 | Acc: 72.05% | Time: 13.52s
2025-05-30 10:35:52,734 - trainer - INFO - Epoch: 8 | Batch: 400/1500 | Loss: 0.7132 | Acc: 71.99% | Time: 13.71s
2025-05-30 10:35:52,917 - trainer - INFO - Epoch: 8 | Batch: 450/1500 | Loss: 0.7121 | Acc: 72.01% | Time: 13.89s
2025-05-30 10:35:53,099 - trainer - INFO - Epoch: 8 | Batch: 500/1500 | Loss: 0.7111 | Acc: 72.01% | Time: 14.07s
2025-05-30 10:35:53,279 - trainer - INFO - Epoch: 8 | Batch: 550/1500 | Loss: 0.7130 | Acc: 71.87% | Time: 14.25s
2025-05-30 10:35:53,461 - trainer - INFO - Epoch: 8 | Batch: 600/1500 | Loss: 0.7117 | Acc: 71.92% | Time: 14.43s
2025-05-30 10:35:53,641 - trainer - INFO - Epoch: 8 | Batch: 650/1500 | Loss: 0.7108 | Acc: 71.93% | Time: 14.61s
2025-05-30 10:35:53,823 - trainer - INFO - Epoch: 8 | Batch: 700/1500 | Loss: 0.7094 | Acc: 72.00% | Time: 14.80s
2025-05-30 10:35:54,004 - trainer - INFO - Epoch: 8 | Batch: 750/1500 | Loss: 0.7104 | Acc: 71.97% | Time: 14.98s
2025-05-30 10:35:54,186 - trainer - INFO - Epoch: 8 | Batch: 800/1500 | Loss: 0.7094 | Acc: 71.94% | Time: 15.16s
2025-05-30 10:35:54,365 - trainer - INFO - Epoch: 8 | Batch: 850/1500 | Loss: 0.7106 | Acc: 71.88% | Time: 15.34s
2025-05-30 10:35:54,552 - trainer - INFO - Epoch: 8 | Batch: 900/1500 | Loss: 0.7099 | Acc: 71.91% | Time: 15.52s
2025-05-30 10:35:54,732 - trainer - INFO - Epoch: 8 | Batch: 950/1500 | Loss: 0.7098 | Acc: 71.96% | Time: 15.70s
2025-05-30 10:35:54,913 - trainer - INFO - Epoch: 8 | Batch: 1000/1500 | Loss: 0.7094 | Acc: 71.98% | Time: 15.88s
2025-05-30 10:35:55,095 - trainer - INFO - Epoch: 8 | Batch: 1050/1500 | Loss: 0.7093 | Acc: 71.99% | Time: 16.07s
2025-05-30 10:35:55,276 - trainer - INFO - Epoch: 8 | Batch: 1100/1500 | Loss: 0.7096 | Acc: 71.99% | Time: 16.25s
2025-05-30 10:35:55,457 - trainer - INFO - Epoch: 8 | Batch: 1150/1500 | Loss: 0.7103 | Acc: 71.97% | Time: 16.43s
2025-05-30 10:35:55,637 - trainer - INFO - Epoch: 8 | Batch: 1200/1500 | Loss: 0.7106 | Acc: 71.98% | Time: 16.61s
2025-05-30 10:35:55,819 - trainer - INFO - Epoch: 8 | Batch: 1250/1500 | Loss: 0.7104 | Acc: 71.98% | Time: 16.79s
2025-05-30 10:35:56,002 - trainer - INFO - Epoch: 8 | Batch: 1300/1500 | Loss: 0.7102 | Acc: 71.97% | Time: 16.97s
2025-05-30 10:35:56,183 - trainer - INFO - Epoch: 8 | Batch: 1350/1500 | Loss: 0.7107 | Acc: 71.95% | Time: 17.15s
2025-05-30 10:35:56,364 - trainer - INFO - Epoch: 8 | Batch: 1400/1500 | Loss: 0.7106 | Acc: 71.94% | Time: 17.34s
2025-05-30 10:35:56,543 - trainer - INFO - Epoch: 8 | Batch: 1450/1500 | Loss: 0.7110 | Acc: 71.94% | Time: 17.51s
2025-05-30 10:35:56,728 - trainer - INFO - Epoch: 8 | Batch: 1500/1500 | Loss: 0.7107 | Acc: 71.96% | Time: 17.70s
2025-05-30 10:36:09,689 - trainer - INFO - 验证 | Loss: 0.6621 | Acc: 74.12%
2025-05-30 10:36:09,697 - trainer - INFO - 最佳模型已保存，epoch 8，验证损失: 0.6621
2025-05-30 10:36:09,697 - trainer - INFO - 训练完成。最佳验证损失: 0.6621，在epoch 8。
2025-05-30 10:36:10,101 - utils - INFO - 训练历史图已保存至 ./outputs\training_history.png
2025-05-30 10:36:10,119 - trainer - INFO - 已加载检查点，来自epoch 8，验证损失: 0.6621，验证准确率: 74.12%
2025-05-30 10:36:10,119 - __main__ - INFO - 在验证集上评估LSTM模型...
2025-05-30 10:36:22,515 - utils - INFO - 评估 | Loss: 0.6621 | Acc: 74.12%
2025-05-30 10:36:22,961 - utils - INFO - 混淆矩阵已保存至 ./outputs\confusion_matrix.png
2025-05-30 10:36:23,020 - __main__ - INFO - 分类报告:
              precision    recall  f1-score       support
BENIGN         0.867863  0.991998  0.925788   3999.000000
DNS            0.961180  0.464250  0.626096   4000.000000
LDAP           0.651414  0.754500  0.699178   4000.000000
MSSQL          0.666126  0.924250  0.774241   4000.000000
NTP            0.863412  0.875500  0.869414   4000.000000
NetBIOS        0.879815  0.713750  0.788130   4000.000000
SNMP           0.674892  0.745250  0.708328   4000.000000
SSDP           0.747132  0.374500  0.498918   4000.000000
Syn            0.986944  0.926000  0.955501   4000.000000
TFTP           0.879902  0.987250  0.930490   4000.000000
UDP            0.474662  0.676750  0.557972   4000.000000
UDP-lag        0.504663  0.460000  0.481297   4000.000000
accuracy       0.741161  0.741161  0.741161      0.741161
macro avg      0.763167  0.741166  0.734613  47999.000000
weighted avg   0.763165  0.741161  0.734609  47999.000000
2025-05-30 10:36:36,033 - utils - INFO - ROC曲线已保存至 ./outputs\roc_curves.png
2025-05-30 10:36:36,033 - __main__ - INFO - 导出模型为ONNX格式...
2025-05-30 10:36:36,174 - utils - INFO - 模型已导出为ONNX格式: ./outputs\ddos_detector.onnx
2025-05-30 10:36:36,196 - utils - INFO - ONNX模型验证通过。
2025-05-30 10:36:36,196 - __main__ - INFO - LSTM模型训练和评估完成。结果保存到 ./outputs
2025-05-30 10:36:36,212 - __main__ - INFO - 加载数据集用于XGBoost训练...
2025-05-30 10:36:36,212 - data - INFO - 加载预处理器从: ./outputs\preprocessor.pkl
2025-05-30 10:36:36,213 - data - INFO - 预处理器已从 ./outputs\preprocessor.pkl 加载，PCA维度: 30
2025-05-30 10:36:36,213 - data - INFO - 预处理器加载成功
2025-05-30 10:36:36,213 - data - INFO - 开始数据处理流水线，模式: 验证
2025-05-30 10:36:36,213 - data - INFO - 开始读取文件: train_dataset.csv
2025-05-30 10:36:36,218 - data - INFO - CSV文件包含 45 个列
2025-05-30 10:36:36,218 - data - INFO - 将读取 45 列: 44 个特征列和 1 个标签列
2025-05-30 10:36:36,682 - data - INFO - 文件 train_dataset.csv 读取完成，shape=(192000, 45)
2025-05-30 10:36:36,686 - data - INFO - 开始数据清洗
2025-05-30 10:36:36,686 - data - INFO - 原始数据形状: (192000, 45)
2025-05-30 10:36:36,889 - data - INFO - 移除重复记录后剩余 191996 条记录
2025-05-30 10:36:36,901 - data - INFO - 处理前缺失值总数: 0
2025-05-30 10:36:37,107 - data - INFO - 处理了 364441 个异常值
2025-05-30 10:36:37,107 - data - INFO - 数据清洗完成，最终形状: (191996, 45)
2025-05-30 10:36:37,107 - data - INFO - 开始特征预处理
2025-05-30 10:36:37,256 - data - INFO - 找到 46 个数值特征
2025-05-30 10:36:37,260 - data - INFO - 验证阶段使用 46 个特征
2025-05-30 10:36:37,486 - data - INFO - PCA降维完成，最终特征维数: 30
2025-05-30 10:36:37,487 - data - INFO - 标签one-hot编码维数: 12
2025-05-30 10:36:37,543 - data - INFO - 最终特征形状: (191996, 30), 标签形状: (191996, 12)
2025-05-30 10:36:37,543 - data - INFO - 类别数量: 12
2025-05-30 10:36:37,543 - data - INFO - 数据处理流水线完成
2025-05-30 10:36:37,550 - data - INFO - 特征数据类型: float64
2025-05-30 10:36:37,550 - data - INFO - 标签数据类型: float64
2025-05-30 10:36:37,567 - data - INFO - 特征形状: torch.Size([191996, 30]), 类型: torch.float32
2025-05-30 10:36:37,568 - data - INFO - 标签形状: torch.Size([191996, 12]), 类型: torch.float32
2025-05-30 10:36:37,568 - data - INFO - 标签类别数: 12
2025-05-30 10:36:37,568 - __main__ - INFO - XGBoost训练数据集大小: 191996
2025-05-30 10:36:37,568 - trainer - INFO - XGBoost训练器初始化完成，输出目录: ./outputs\xgb_models
2025-05-30 10:36:37,568 - __main__ - INFO - 开始训练XGBoost分类器...
2025-05-30 10:36:37,568 - trainer - INFO - 训练 UDP (10) vs UDP-lag (11) XGBoost分类器
2025-05-30 10:36:37,602 - trainer - INFO - 类别 UDP (10) 样本数: 16000
2025-05-30 10:36:37,603 - trainer - INFO - 类别 UDP-lag (11) 样本数: 16000
2025-05-30 10:36:37,615 - trainer - INFO - 开始XGBoost网格搜索...
2025-05-30 10:38:04,433 - trainer - INFO - 最优参数: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50, 'subsample': 0.9}
2025-05-30 10:38:04,707 - trainer - INFO - 测试集准确率: 0.7866
2025-05-30 10:38:04,722 - trainer - INFO - 分类报告:
              precision    recall  f1-score   support

           0       0.74      0.89      0.81      3200
           1       0.86      0.68      0.76      3200

    accuracy                           0.79      6400
   macro avg       0.80      0.79      0.78      6400
weighted avg       0.80      0.79      0.78      6400

2025-05-30 10:38:04,727 - trainer - INFO - XGBoost模型已保存至: ./outputs\xgb_models\xgb_model_10_11.pkl
2025-05-30 10:38:04,728 - trainer - INFO - 训练 NetBIOS (5) vs SSDP (7) XGBoost分类器
2025-05-30 10:38:04,798 - trainer - INFO - 类别 NetBIOS (5) 样本数: 16000
2025-05-30 10:38:04,801 - trainer - INFO - 类别 SSDP (7) 样本数: 16000
2025-05-30 10:38:04,821 - trainer - INFO - 开始XGBoost网格搜索...
2025-05-30 10:39:15,605 - trainer - INFO - 最优参数: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50, 'subsample': 0.9}
2025-05-30 10:39:15,848 - trainer - INFO - 测试集准确率: 0.9838
2025-05-30 10:39:15,859 - trainer - INFO - 分类报告:
              precision    recall  f1-score   support

           0       0.98      0.99      0.98      3200
           1       0.99      0.98      0.98      3200

    accuracy                           0.98      6400
   macro avg       0.98      0.98      0.98      6400
weighted avg       0.98      0.98      0.98      6400

2025-05-30 10:39:15,862 - trainer - INFO - XGBoost模型已保存至: ./outputs\xgb_models\xgb_model_5_7.pkl
2025-05-30 10:39:15,864 - trainer - INFO - 训练 LDAP (2) vs Syn (8) XGBoost分类器
2025-05-30 10:39:15,934 - trainer - INFO - 类别 LDAP (2) 样本数: 16000
2025-05-30 10:39:15,937 - trainer - INFO - 类别 Syn (8) 样本数: 16000
2025-05-30 10:39:15,953 - trainer - INFO - 开始XGBoost网格搜索...
2025-05-30 10:39:42,273 - trainer - INFO - 最优参数: {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 200, 'subsample': 1.0}
2025-05-30 10:39:42,525 - trainer - INFO - 测试集准确率: 0.9994
2025-05-30 10:39:42,539 - trainer - INFO - 分类报告:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3200
           1       1.00      1.00      1.00      3200

    accuracy                           1.00      6400
   macro avg       1.00      1.00      1.00      6400
weighted avg       1.00      1.00      1.00      6400

2025-05-30 10:39:42,546 - trainer - INFO - XGBoost模型已保存至: ./outputs\xgb_models\xgb_model_2_8.pkl
2025-05-30 10:39:42,548 - trainer - INFO - 训练 TFTP (9) vs UDP (10) XGBoost分类器
2025-05-30 10:39:42,613 - trainer - INFO - 类别 TFTP (9) 样本数: 16000
2025-05-30 10:39:42,616 - trainer - INFO - 类别 UDP (10) 样本数: 16000
2025-05-30 10:39:42,634 - trainer - INFO - 开始XGBoost网格搜索...
2025-05-30 10:40:05,994 - trainer - INFO - 最优参数: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.8}
2025-05-30 10:40:06,146 - trainer - INFO - 测试集准确率: 1.0000
2025-05-30 10:40:06,160 - trainer - INFO - 分类报告:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3200
           1       1.00      1.00      1.00      3200

    accuracy                           1.00      6400
   macro avg       1.00      1.00      1.00      6400
weighted avg       1.00      1.00      1.00      6400

2025-05-30 10:40:06,165 - trainer - INFO - XGBoost模型已保存至: ./outputs\xgb_models\xgb_model_9_10.pkl
2025-05-30 10:40:06,167 - trainer - INFO - 训练 BENIGN (0) vs NTP (4) XGBoost分类器
2025-05-30 10:40:06,237 - trainer - INFO - 类别 BENIGN (0) 样本数: 15999
2025-05-30 10:40:06,240 - trainer - INFO - 类别 NTP (4) 样本数: 15997
2025-05-30 10:40:06,263 - trainer - INFO - 开始XGBoost网格搜索...
2025-05-30 10:40:48,154 - trainer - INFO - 最优参数: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 200, 'subsample': 1.0}
2025-05-30 10:40:48,722 - trainer - INFO - 测试集准确率: 0.9977
2025-05-30 10:40:48,734 - trainer - INFO - 分类报告:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3200
           1       1.00      1.00      1.00      3200

    accuracy                           1.00      6400
   macro avg       1.00      1.00      1.00      6400
weighted avg       1.00      1.00      1.00      6400

2025-05-30 10:40:48,740 - trainer - INFO - XGBoost模型已保存至: ./outputs\xgb_models\xgb_model_0_4.pkl
2025-05-30 10:40:48,742 - trainer - INFO - 训练 BENIGN (0) vs TFTP (9) XGBoost分类器
2025-05-30 10:40:48,808 - trainer - INFO - 类别 BENIGN (0) 样本数: 15999
2025-05-30 10:40:48,811 - trainer - INFO - 类别 TFTP (9) 样本数: 16000
2025-05-30 10:40:48,831 - trainer - INFO - 开始XGBoost网格搜索...
2025-05-30 10:41:21,774 - trainer - INFO - 最优参数: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}
2025-05-30 10:41:22,024 - trainer - INFO - 测试集准确率: 0.9984
2025-05-30 10:41:22,039 - trainer - INFO - 分类报告:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3200
           1       1.00      1.00      1.00      3200

    accuracy                           1.00      6400
   macro avg       1.00      1.00      1.00      6400
weighted avg       1.00      1.00      1.00      6400

2025-05-30 10:41:22,045 - trainer - INFO - XGBoost模型已保存至: ./outputs\xgb_models\xgb_model_0_9.pkl
2025-05-30 10:41:22,047 - __main__ - INFO - XGBoost分类器 UDP vs UDP-lag 准确率: 0.7866
2025-05-30 10:41:22,048 - __main__ - INFO - XGBoost分类器 NetBIOS vs SSDP 准确率: 0.9838
2025-05-30 10:41:22,048 - __main__ - INFO - XGBoost分类器 LDAP vs Syn 准确率: 0.9994
2025-05-30 10:41:22,048 - __main__ - INFO - XGBoost分类器 TFTP vs UDP 准确率: 1.0000
2025-05-30 10:41:22,048 - __main__ - INFO - XGBoost分类器 BENIGN vs NTP 准确率: 0.9977
2025-05-30 10:41:22,048 - __main__ - INFO - XGBoost分类器 BENIGN vs TFTP 准确率: 0.9984
2025-05-30 10:41:22,076 - data - INFO - 加载预处理器从: ./outputs\preprocessor.pkl
2025-05-30 10:41:22,078 - data - INFO - 预处理器已从 ./outputs\preprocessor.pkl 加载，PCA维度: 30
2025-05-30 10:41:22,078 - data - INFO - 预处理器加载成功
2025-05-30 10:41:22,078 - data - INFO - 开始数据处理流水线，模式: 验证
2025-05-30 10:41:22,078 - data - INFO - 开始读取文件: test_dataset.csv
2025-05-30 10:41:22,106 - data - INFO - CSV文件包含 45 个列
2025-05-30 10:41:22,106 - data - INFO - 将读取 45 列: 44 个特征列和 1 个标签列
2025-05-30 10:41:22,239 - data - INFO - 文件 test_dataset.csv 读取完成，shape=(48000, 45)
2025-05-30 10:41:22,240 - data - INFO - 开始数据清洗
2025-05-30 10:41:22,241 - data - INFO - 原始数据形状: (48000, 45)
2025-05-30 10:41:22,277 - data - INFO - 移除重复记录后剩余 47999 条记录
2025-05-30 10:41:22,280 - data - INFO - 处理前缺失值总数: 0
2025-05-30 10:41:22,351 - data - INFO - 处理了 90815 个异常值
2025-05-30 10:41:22,351 - data - INFO - 数据清洗完成，最终形状: (47999, 45)
2025-05-30 10:41:22,351 - data - INFO - 开始特征预处理
2025-05-30 10:41:22,393 - data - INFO - 找到 46 个数值特征
2025-05-30 10:41:22,395 - data - INFO - 验证阶段使用 46 个特征
2025-05-30 10:41:22,454 - data - INFO - PCA降维完成，最终特征维数: 30
2025-05-30 10:41:22,454 - data - INFO - 标签one-hot编码维数: 12
2025-05-30 10:41:22,472 - data - INFO - 最终特征形状: (47999, 30), 标签形状: (47999, 12)
2025-05-30 10:41:22,472 - data - INFO - 类别数量: 12
2025-05-30 10:41:22,472 - data - INFO - 数据处理流水线完成
2025-05-30 10:41:22,477 - data - INFO - 特征数据类型: float64
2025-05-30 10:41:22,477 - data - INFO - 标签数据类型: float64
2025-05-30 10:41:22,480 - data - INFO - 特征形状: torch.Size([47999, 30]), 类型: torch.float32
2025-05-30 10:41:22,480 - data - INFO - 标签形状: torch.Size([47999, 12]), 类型: torch.float32
2025-05-30 10:41:22,480 - data - INFO - 标签类别数: 12
2025-05-30 10:41:22,486 - __main__ - INFO - 初始化XGBoost级联模型...
2025-05-30 10:41:22,490 - model - INFO - 已加载XGBoost分类器: 10 vs 11
2025-05-30 10:41:22,494 - model - INFO - 已加载XGBoost分类器: 5 vs 7
2025-05-30 10:41:22,500 - model - INFO - 已加载XGBoost分类器: 2 vs 8
2025-05-30 10:41:22,503 - model - INFO - 已加载XGBoost分类器: 9 vs 10
2025-05-30 10:41:22,511 - model - INFO - 已加载XGBoost分类器: 0 vs 4
2025-05-30 10:41:22,519 - model - INFO - 已加载XGBoost分类器: 0 vs 9
2025-05-30 10:41:22,519 - __main__ - INFO - 评估XGBOOST级联模型...
2025-05-30 10:41:59,926 - __main__ - INFO - 基础模型准确率: 0.7412
2025-05-30 10:41:59,926 - __main__ - INFO - XGBOOST级联模型准确率: 0.7735
2025-05-30 10:41:59,926 - __main__ - INFO - 精度提升: 3.23%
2025-05-30 10:42:00,400 - utils - INFO - 混淆矩阵已保存至 ./outputs\xgboost_cascade_confusion_matrix.png
2025-05-30 10:42:00,408 - __main__ - INFO - 类别 UDP vs UDP-lag:
2025-05-30 10:42:00,409 - __main__ - INFO -   基础模型准确率: 0.5684
2025-05-30 10:42:00,409 - __main__ - INFO -   级联模型准确率: 0.7265
2025-05-30 10:42:00,409 - __main__ - INFO -   精度提升: 15.81%
2025-05-30 10:42:00,417 - __main__ - INFO - 类别 NetBIOS vs SSDP:
2025-05-30 10:42:00,417 - __main__ - INFO -   基础模型准确率: 0.5441
2025-05-30 10:42:00,417 - __main__ - INFO -   级联模型准确率: 0.5454
2025-05-30 10:42:00,417 - __main__ - INFO -   精度提升: 0.13%
2025-05-30 10:42:00,427 - __main__ - INFO - 类别 LDAP vs Syn:
2025-05-30 10:42:00,428 - __main__ - INFO -   基础模型准确率: 0.8403
2025-05-30 10:42:00,428 - __main__ - INFO -   级联模型准确率: 0.8405
2025-05-30 10:42:00,428 - __main__ - INFO -   精度提升: 0.02%
2025-05-30 10:42:00,437 - __main__ - INFO - 类别 TFTP vs UDP:
2025-05-30 10:42:00,437 - __main__ - INFO -   基础模型准确率: 0.8320
2025-05-30 10:42:00,437 - __main__ - INFO -   级联模型准确率: 0.9214
2025-05-30 10:42:00,437 - __main__ - INFO -   精度提升: 8.94%
2025-05-30 10:42:00,446 - __main__ - INFO - 类别 BENIGN vs NTP:
2025-05-30 10:42:00,446 - __main__ - INFO -   基础模型准确率: 0.9337
2025-05-30 10:42:00,446 - __main__ - INFO -   级联模型准确率: 0.9679
2025-05-30 10:42:00,446 - __main__ - INFO -   精度提升: 3.41%
2025-05-30 10:42:00,454 - __main__ - INFO - 类别 BENIGN vs TFTP:
2025-05-30 10:42:00,454 - __main__ - INFO -   基础模型准确率: 0.9896
2025-05-30 10:42:00,454 - __main__ - INFO -   级联模型准确率: 0.9897
2025-05-30 10:42:00,454 - __main__ - INFO -   精度提升: 0.01%
2025-05-30 10:42:00,458 - __main__ - INFO - DDoS检测系统训练成功完成！
2025-05-30 10:42:00,458 - __main__ - INFO - 使用的级联模型类型: XGBOOST
